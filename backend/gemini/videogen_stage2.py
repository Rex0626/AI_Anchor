import os
import json
import re
from datetime import timedelta
from moviepy.editor import VideoFileClip
from vertexai.generative_models import Part
from haystack_integrations.components.generators.google_vertex import VertexAIGeminiGenerator
from haystack import component, Pipeline
from haystack.components.builders import PromptBuilder
from tqdm import tqdm

# ========== 1. è¨­å®šèˆ‡æ†‘è­‰ ==========
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
cred_path = os.path.join(PROJECT_ROOT, "credentials", "ai-anchor-462506-7887b7105f6a.json")
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = cred_path

# ========== 2. é—œéµåƒæ•¸ ==========
SYLLABLES_PER_SEC = 4.8       
MIN_EVENT_DURATION = 1.0      
MAX_RALLY_DURATION = 6.0
MIN_GAP_DURATION = 3.0        
MAX_INTRO_OUTRO_SYLLABLES = 30 
MERGE_THRESHOLD = 1.2 # [æ–°å¢] å¼·åˆ¶åˆä½µé–¾å€¼ï¼šè‹¥ç‰‡æ®µçŸ­æ–¼ 1.2 ç§’ï¼Œå¼·åˆ¶åˆä½µåˆ°ä¸‹ä¸€æ®µ

# å…¨åŸŸæ­·å²ç´€éŒ„
NARRATIVE_HISTORY = [] 
HISTORY_WINDOW_SIZE = 3 

# ========== 3. å·¥å…·å‡½æ•¸ ==========
def seconds_to_timecode(seconds):
    m, s = divmod(seconds, 60)
    h, m = divmod(m, 60)
    return f"{int(h)}:{int(m):02d}:{s:04.1f}"

def format_duration(seconds):
    m = int(seconds // 60)
    s = seconds % 60
    return f"{m}:{s:04.1f}"

def parse_time_str(t_str):
    try:
        if not t_str: return 0.0
        parts = t_str.strip().split(':')
        sec = 0.0
        if len(parts) == 3: sec += float(parts[-3]) * 3600
        if len(parts) >= 2: sec += float(parts[-2]) * 60
        sec += float(parts[-1])
        return sec
    except: return 0.0

def estimate_speech_time(text):
    if not text: return 0.0
    chinese_chars = re.findall(r'[\u4e00-\u9fff]', text)
    text_no_zh = re.sub(r'[\u4e00-\u9fff]', ' ', text)
    text_clean_en = re.sub(r'[^\w\s]', '', text_no_zh)
    english_words = text_clean_en.split()
    count_punc = len(re.findall(r'[ï¼Œã€‚ï¼,.]', text))
    total_units = (len(chinese_chars) * 1.0) + (len(english_words) * 1.3) + (count_punc * 0.4)
    return total_units / SYLLABLES_PER_SEC

# ========== 4. Pipeline åˆå§‹åŒ– ==========
@component
class AddVideo2Prompt:
    @component.output_types(prompt=list)
    def run(self, uri: str, prompt: str):
        return {"prompt": [Part.from_uri(uri, mime_type="video/mp4"), prompt]}

@component
class GeminiGenerator:
    def __init__(self, project_id, location, model):
        self.project_id, self.location, self.model = project_id, location, model
    @component.output_types(replies=list)
    def run(self, prompt: list):
        generator = VertexAIGeminiGenerator(project_id=self.project_id, location=self.location, model=self.model)
        return {"replies": generator.run(prompt)["replies"]}

# ========== 5. Prompt æ¨¡æ¿ ==========
narrative_template = """ 
1. è§’è‰²è¨­å®š (Role)
ä½ æ˜¯ä¸€ä½**è³‡æ·±ã€ç†±è¡€ä¸”å…·å‚™æˆ°è¡“æ´å¯ŸåŠ›**çš„é ‚ç´šè³½äº‹ä¸»æ’­ã€‚
ä½ çš„ç›®æ¨™æ˜¯é€éè²éŸ³å°‡è§€çœ¾å¸¶å…¥è³½å ´ã€‚ä½ çš„è§£èªªé¢¨æ ¼ï¼š
- **æ‹’çµ•å¹³é‹ªç›´æ•˜**ï¼šä¸è¦ç•¶ã€Œå ±å¹•å“¡ã€ï¼Œè¦ç•¶ã€Œèªªæ›¸äººã€ã€‚
- **å¼·èª¿å› æœé—œä¿‚**ï¼šè§£é‡‹å‹•ä½œèƒŒå¾Œçš„æ„åœ–èˆ‡çµæœï¼ˆä¾‹å¦‚ï¼šä¸åªæ˜¯èªªã€Œä»–æ®ºçƒã€ï¼Œè¦èªªã€Œé€™è¨˜æ®ºçƒç ´å£äº†å°æ‰‹é‡å¿ƒã€ï¼‰ã€‚
- **å£èªåŒ– (TTS Friendly)**ï¼šä½¿ç”¨é©åˆæœ—è®€çš„çŸ­å¥ï¼Œé¿å…ç”Ÿç¡¬çš„æ›¸é¢ç”¨èªã€‚
- **æ³¨æ„ç´°ç¯€**ï¼šè«‹å–„ç”¨detailä¾†è±å¯Œæ–‡æœ¬è§£èªªã€‚

2. ä¸Šä¸‹æ–‡è³‡è¨Š (Context)
- **æ­·å²æˆ°æ³ (Flow)**ï¼š
{{ prev_context }}
*(è«‹ç¹¼æ‰¿ä¸Šè¿°çš„èªæ°£èˆ‡æƒ…ç·’ï¼Œç¢ºä¿è§£èªªæµæš¢ä¸æ–·å±¤)*

- **è¼¸å…¥ä¾†æº**ï¼šçµåˆ **JSON äº‹ä»¶éˆ** èˆ‡ **è¦–è¦ºç•«é¢** é€²è¡Œè§£èªªã€‚

3. ä»»å‹™åŸ·è¡Œ (Tasks)
ä½ çš„å·¥ä½œæ˜¯è¦å°‡ä¸€ç³»åˆ—çš„äº‹ä»¶è½‰åŒ–ç‚ºç”Ÿå‹•çš„è§£èªªæ–‡æœ¬ï¼š

- **è§£è®€è¦å‰‡**ï¼š[åˆ†é¡] player - action (detail)
    *ç¯„ä¾‹ï¼š`[Offense] æˆ´è³‡ç© - æ®ºçƒ (è²¼ç¶²)`*

- **èªæ°£èˆ‡ç¯€å¥æŒ‡å¼• (Tone & Pacing)**ï¼š
    - **ğŸŸ¢ [Setup] / [Exchange] (æˆ°è¡“åˆ†æ)**ï¼š
        * **èªæ°£**ï¼šå†·éœã€æ¸…æ™°ã€‚
        * **é‡é»**ï¼šæè¿°çƒè·¯ä½ˆå±€ã€‚ä¾‹å¦‚ï¼šã€Œé›™æ–¹é‚„åœ¨äº’ç›¸è©¦æ¢ç¶²å‰æ‰‹æ„Ÿ...ã€
    - **ğŸŸ¡ [Offense] / [Defense] (æ”»é˜²å¼µåŠ›)**ï¼š
        * **èªæ°£**ï¼š**æ€¥ä¿ƒã€ç·Šæ¹Šï¼**
        * **é‡é»**ï¼šä½¿ç”¨ã€Œå‹•ä½œ-åæ‡‰ã€é‚è¼¯ã€‚ä¾‹å¦‚ï¼šã€Œå°æˆ´çªç„¶èµ·è·³é‡æ®ºï¼é›¨è²åæ‡‰å¾ˆå¿«ç›´æ¥æ“‹å›ï¼ã€
    - **ğŸ”´ [Score] / [Result] (æƒ…ç·’é‡‹æ”¾)**ï¼š
        * **èªæ°£**ï¼š**é«˜æ˜‚ã€æ¿€å‹•ï¼**
        * **é‡é»**ï¼šè®šå˜†å¾—åˆ†æ‰‹æ®µæˆ–æƒ‹æƒœå¤±èª¤ã€‚ä¾‹å¦‚ï¼šã€Œå“‡ï¼é€™çƒæ®ºå¾—å¤ªåˆé‘½äº†ï¼å®Œå…¨æ²’æ©Ÿæœƒï¼ã€
    - **ğŸ”µ [Gap] / [Intro] / [Outro] (å‘¼å¸ç•™ç™½)**ï¼š
        * **èªæ°£**ï¼šèˆ’ç·©ã€æ„Ÿæ€§ã€‚
        * **é‡é»**ï¼šå¡«è£œç©ºç™½ï¼Œä½†ä¸è¦å¡«æ»¿ã€‚è©•è«–ä¸Šä¸€çƒçš„å¿ƒç†åšå¼ˆï¼Œæˆ–é å‘Šä¸‹ä¸€çƒã€‚

4. åš´æ ¼ç¦ä»¤ (Strict Prohibitions)
â›”ï¸ **é•è¦å°‡å°è‡´ç³»çµ±éŒ¯èª¤ï¼š**
- **ğŸˆ² ç¦æ­¢æµæ°´å¸³**ï¼šçµ•å°ä¸è¦ä½¿ç”¨ã€Œç„¶å¾Œ...æ¥è‘—...ã€é€™ç¨®é€£æ¥è©ã€‚è«‹ç”¨**å› æœé—œä¿‚**ä¸²è¯ï¼ˆã€Œé€¼å¾—å°æ‰‹...ã€ã€ã€Œå°è‡´...ã€ï¼‰ã€‚
- **ğŸˆ² ç¦æ­¢é–“éš™å¹»è¦º**ï¼šåœ¨ `[Gap]` çµ•å°ä¸èƒ½æè¿°æ–°çš„æ“Šçƒå‹•ä½œï¼ˆæ®ºçƒ/ç™¼çƒï¼‰ã€‚åªèƒ½è¬›è©•è«–ã€‚
- **ğŸˆ² ç¦æ­¢æœªåœå…ˆçŸ¥**ï¼šè‹¥ `[Score]` æœªå‡ºç¾ï¼Œä¸å¯æå‰å®£å‘Šå¾—åˆ†ã€‚
- **ğŸˆ² åš´æ ¼å­—æ•¸æ§åˆ¶**ï¼š`constraint` æ˜¯ç‰©ç†é™åˆ¶ã€‚**å¯§å¯è©±å°‘ç²¾ç°¡ï¼Œçµ•ä¸è¶…æ™‚çˆ†éŸ³ã€‚**

5. è¼¸å‡ºæ ¼å¼
è¼¸å‡ºç´” JSON é™£åˆ—ï¼ŒåŒ…å« `id` å’Œ `text` å…©å€‹æ¬„ä½ã€‚

6. ç¯„ä¾‹ (Example)
**è¼¸å…¥:**
[
    {"id": 0, "constraint": "é™ 14 éŸ³ç¯€", "content": "[Serve] æˆ´è³‡ç© - ç™¼çƒ (éé«˜) -> [Offense] é™³é›¨è² - æ’²çƒ (ä¸‹å£“)"},
    {"id": 1, "constraint": "é™ 8 éŸ³ç¯€", "content": "[Score] ç„¡ - ç•Œå…§å¾—åˆ†"},
    {"id": 2, "constraint": "é™ 12 éŸ³ç¯€", "content": "[Gap] å°æ‰‹æ‡Šæƒ±"}
]
**è¼¸å‡º:**
[
    {"id": 0, "text": "å°æˆ´é€™çƒç™¼é«˜äº†ï¼é™³é›¨è²æ²’æ”¾éæ©Ÿæœƒç›´æ¥ä¸‹å£“ï¼"},
    {"id": 1, "text": "è½åœ°å¾—åˆ†ï¼é€™çƒæŠ“å¾—å¤ªæº–äº†ï¼"},
    {"id": 2, "text": "å°æˆ´è‡‰ä¸Šéœ²å‡ºäº†æ‡Šæƒ±çš„è¡¨æƒ…ã€‚"}
]

ğŸ“Š **å¾…è™•ç†æ•¸æ“šï¼š**
{{ event_data }}

è«‹è¼¸å‡º JSONï¼š
"""

prompt_builder = PromptBuilder(template=narrative_template, required_variables=["event_data","prev_context"])

add_video_s2 = AddVideo2Prompt()
gemini_s2 = GeminiGenerator(project_id="ai-anchor-462506", location="us-central1", model="gemini-2.5-flash")

pipeline_s2 = Pipeline()
pipeline_s2.add_component(instance=prompt_builder, name="prompt_builder")
pipeline_s2.add_component(instance=add_video_s2, name="add_video")
pipeline_s2.add_component(instance=gemini_s2, name="llm")
pipeline_s2.connect("prompt_builder.prompt", "add_video.prompt")
pipeline_s2.connect("add_video.prompt", "llm.prompt")

# ========== 6. è¼”åŠ©å‡½å¼ (å«æœ€çµ‚é˜²ç·š) ==========
def _flush_chunk(results_list, chunk_data, global_counter_ref):
    dur = chunk_data["end"] - chunk_data["start"]
    limit = int(dur * SYLLABLES_PER_SEC)
    should_keep = False
    
    # åˆ¤æ–·é¡å‹
    is_gap = "é–“éš™" in chunk_data.get("info", "") or "Gap" in chunk_data.get("info", "")
    is_crucial = chunk_data.get("is_crucial", False)

    # ğŸ”¥ æœ€çµ‚é˜²ç·šï¼šè‹¥é€šéäº†è¿´åœˆçš„ç¯©é¸ï¼Œé€™è£¡åšæœ€å¾Œçš„æ ¼å¼ä¿éšœ
    if is_crucial or is_gap:
        # é—œéµæ™‚åˆ»/é–“éš™ï¼šå¼·åˆ¶ä¿ç•™ä¸¦çµ¦äºˆæœ€å°å­—æ•¸ç©ºé–“
        limit = max(limit, 6) 
        should_keep = True
    else:
        # æ™®é€š Rallyï¼šè‹¥é‚„æ˜¯å¤ªçŸ­ä¸”æ²’è¢«åˆä½µï¼Œä¸Ÿæ£„ (é€™æ˜¯æœ€å¾Œä¸€é“æ¿¾ç¶²)
        if limit >= 4:
            should_keep = True

    if should_keep:
        results_list.append({
            "global_id": global_counter_ref[0], 
            "start_sec": chunk_data["start"], 
            "end_sec": chunk_data["end"], 
            "limit": limit, 
            "info": chunk_data["info"]
        })
        global_counter_ref[0] += 1


# ========== 7. æ ¸å¿ƒåŠŸèƒ½ï¼šè™•ç†å–®ä¸€å½±ç‰‡ (å·²ä¿®æ­£æ™‚é–“è»¸æ’è»¸é‚è¼¯) ==========
def process_single_video_stage2(video_path, event_json_path, output_folder):
    global NARRATIVE_HISTORY

    os.makedirs(output_folder, exist_ok=True)
    base_name = os.path.splitext(os.path.basename(video_path))[0]
    
    try:
        with VideoFileClip(video_path) as clip: total_duration = clip.duration
    except: total_duration = 30.0 

    try:
        with open(event_json_path, 'r', encoding='utf-8') as f: 
            data = json.load(f)
            events = data.get("events", [])
            video_uri = data.get("video_uri", "") or data.get("segment_video_uri", "")
    except Exception as e:
        print(f"âŒ è®€å– JSON å¤±æ•—: {e}")
        return None

    if not events: return None

    # --- A. æ™ºæ…§èšåˆé‚è¼¯ (Smart Aggregation) ---
    narrative_blocks = []
    current_block = []
    block_start_time = 0.0
    
    events.sort(key=lambda x: parse_time_str(x.get("start_time", "0:00")))

    # 1. è™•ç†é–‹å ´
    first_event_start = parse_time_str(events[0].get("start_time", "0:00"))
    if first_event_start > 1.5:
        narrative_blocks.append({
            "type": "INTRO",
            "start": 0.0,
            "end": first_event_start,
            "content": "é–‹å ´/æº–å‚™å‹•ä½œ"
        })

    # 2. éæ­·äº‹ä»¶ä¸¦åˆ†çµ„
    last_event_end = 0.0
    
    for i, event in enumerate(events):
        start = parse_time_str(event.get("start_time"))
        end = parse_time_str(event.get("end_time"))
        if end == 0.0: end = start + 1.0 
        
        cat = event.get("category", "General")
        sub = event.get("subject") or event.get("player", "çƒå“¡")
        act = event.get("action", "")
        det = event.get("detail", "")
        
        event_str = f"[{cat}] {sub} - {act}"
        if det: event_str += f" ({det})"

        gap_from_prev = start - last_event_end
        should_start_new_block = False
        
        if not current_block:
            should_start_new_block = True
        elif gap_from_prev > 2.0: 
            should_start_new_block = True
        else:
            current_block_dur = end - block_start_time
            if current_block_dur > MAX_RALLY_DURATION:
                should_start_new_block = True
        
        if should_start_new_block:
            if current_block:
                narrative_blocks.append({
                    "type": "RALLY",
                    "start": block_start_time,
                    "end": last_event_end,
                    "content": " -> ".join(current_block)
                })
                if gap_from_prev > 2.0:
                    narrative_blocks.append({
                        "type": "GAP",
                        "start": last_event_end,
                        "end": start,
                        "content": "ä¸­å ´é–“éš™/èª¿æ•´"
                    })

            current_block = [event_str]
            block_start_time = start
        else:
            current_block.append(event_str)
        
        last_event_end = end

    if current_block:
        narrative_blocks.append({
            "type": "RALLY",
            "start": block_start_time,
            "end": last_event_end,
            "content": " -> ".join(current_block)
        })

    # 3. è™•ç†çµå°¾
    if total_duration - last_event_end > 2.0:
        narrative_blocks.append({
            "type": "OUTRO",
            "start": last_event_end,
            "end": total_duration,
            "content": "æœ¬æ®µçµæŸ/é‡æ’­ç•«é¢"
        })

    # --- B. æº–å‚™ LLM è¼¸å…¥è³‡æ–™ (å·²ä¿®æ”¹ï¼šä¿å­˜ raw_content) ---
    llm_input_data = []
    final_blocks_map = [] 

    for idx, block in enumerate(narrative_blocks):
        duration = block["end"] - block["start"]
        if duration < 0.5: continue 

        syllable_limit = int(duration * SYLLABLES_PER_SEC)
        syllable_limit = max(syllable_limit, 6) 
        
        info_text = block["content"]
        if block["type"] == "GAP": info_text = "[Gap] ä¸­å ´ä¼‘æ¯/çƒå“¡ç‰¹å¯«"
        if block["type"] == "INTRO": info_text = "[Intro] æ¯”è³½é–‹å§‹"

        llm_input_data.append({
            "id": idx,
            "constraint": f"é™ {syllable_limit} éŸ³ç¯€",
            "content": info_text
        })
        
        # ğŸ”¥ ä¿®æ”¹è™• 1ï¼šä¿å­˜åŸå§‹å…§å®¹ä»¥ä¾¿å¾ŒçºŒåˆ¤æ–·é¡å‹
        final_blocks_map.append({
            "id": idx,
            "start": block["start"],
            "end": block["end"],
            "type": block["type"],
            "raw_content": info_text.lower() # è½‰å°å¯«å­˜èµ·ä¾†
        })

    # --- C. å‘¼å« LLM ---
    if NARRATIVE_HISTORY:
        recent_history = NARRATIVE_HISTORY[-HISTORY_WINDOW_SIZE:]
        history_str = "\n".join([f"- {h}" for h in recent_history])
    else:
        history_str = "é€™æ˜¯æ¯”è³½çš„ç¬¬ä¸€å€‹ç‰‡æ®µã€‚"

    try:
        res = pipeline_s2.run({
            "add_video": {"uri": video_uri},
            "prompt_builder": {
                "event_data": json.dumps(llm_input_data, ensure_ascii=False, indent=2),
                "prev_context": history_str 
                }
        })
        reply = res["llm"]["replies"][0].strip()
        if "```" in reply:
            reply = re.search(r'\[.*\]', reply, re.DOTALL).group()
        
        generated_list = json.loads(reply)
        generated_map = {item["id"]: item["text"] for item in generated_list}
    except Exception as e:
        print(f"âŒ [Stage 2 LLM éŒ¯èª¤] {e}")
        return None

    # --- D. è¼¸å‡ºçµæœ (å·²ä¿®æ”¹ï¼šå‹•æ…‹æ’è»¸å„ªåŒ–) ---
    
    # ğŸ”¥ å®šç¾©å‹•ä½œå»¶é²è¡¨ (å–®ä½ï¼šç§’)
    DELAY_MAP = {
        "setup": 2.2,    # ç™¼çƒ/æº–å‚™ï¼šå‹•ä½œé•·ï¼Œå¾€å¾Œæ¨ 2.2 ç§’å†è¬›
        "serve": 2.2,    
        "offense": 0.6,  # æ®ºçƒ/é€²æ”»ï¼šæ¨¡æ“¬åæ‡‰æ™‚é–“ 0.6 ç§’
        "smash": 0.6,    
        "defense": 0.8,  # é˜²å®ˆ
        "score": 0.1,    # å¾—åˆ†ï¼šçƒè½åœ°é¦¬ä¸Šå–Š
        "gap": 0.5,      # é–“éš™ï¼šç¨å¾®ç•™ç™½
        "intro": 0.0,    
        "default": 0.8   
    }
    
    MIN_BLOCK_DURATION = 1.3 
    commentary = []
    segment_narrative_text = []
    
    # æŒ‡é‡ï¼šè¨˜éŒ„ä¸Šä¸€å¥è©±çµæŸæ™‚é–“ï¼Œé˜²æ­¢é‡ç–Š
    last_speech_end_time = 0.0

    for block_meta in final_blocks_map:
        bid = block_meta["id"]
        text = generated_map.get(bid, "")
        if not text: continue

        # 1. å–å‡ºåŸå§‹è³‡æ–™
        raw_start = block_meta["start"]
        raw_content = block_meta.get("raw_content", "")
        block_type = block_meta["type"]
        
        # 2. åˆ¤æ–·å»¶é²æ™‚é–“
        adjusted_start = raw_start

        # 4. ğŸ”¥ é˜²é‡ç–Šæ©Ÿåˆ¶
        if adjusted_start < last_speech_end_time + 0.15:
            adjusted_start = last_speech_end_time + 0.15
            
        # 5. è¨ˆç®—çµæŸæ™‚é–“ (åŸºæ–¼æ–‡å­—é•·åº¦å‹•æ…‹ä¼°ç®—)
        estimated_speech_dur = len(text) / SYLLABLES_PER_SEC
        target_duration = max(estimated_speech_dur, MIN_BLOCK_DURATION)
        
        adjusted_end = adjusted_start + target_duration
        
        # 6. é‚Šç•Œæª¢æŸ¥
        if adjusted_end > total_duration:
            adjusted_end = total_duration
            if adjusted_end - adjusted_start < 1.0:
                adjusted_start = max(0, adjusted_end - 1.0)

        # 7. æ›´æ–°æŒ‡é‡
        last_speech_end_time = adjusted_end

        # 8. æƒ…ç·’æ¨™ç±¤
        emotion = "å¹³ç©©"
        if block_type == "RALLY":
            if any(k in raw_content for k in ["offense", "score", "smash", "kill"]):
                emotion = "æ¿€å‹•"
        elif block_type == "GAP":
            emotion = "èˆ’ç·©"

        commentary.append({
            "start_time": seconds_to_timecode(adjusted_start),
            "end_time": seconds_to_timecode(adjusted_end),
            "time_range": format_duration(adjusted_end - adjusted_start),
            "emotion": emotion,
            "text": text
        })
        segment_narrative_text.append(text)

    # æ›´æ–°æ­·å²ç´€éŒ„
    if segment_narrative_text:
        NARRATIVE_HISTORY.append(" ".join(segment_narrative_text))
        if len(NARRATIVE_HISTORY) > 10: NARRATIVE_HISTORY.pop(0)

    # å­˜æª”
    output_path = os.path.join(output_folder, f"{base_name}.json")
    if commentary:
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump({"segment": base_name, "commentary": commentary}, f, ensure_ascii=False, indent=2)
        return output_path
    else:
        return None


# ========== 8. ç¨ç«‹é‹è¡Œæ¨¡å¼ ==========
if __name__ == "__main__":
    video_folder = "D:/Vs.code/AI_Anchor/backend/video_splitter/badminton_segments"
    event_json_folder = "D:/Vs.code/AI_Anchor/backend/gemini/event_analysis_output"
    output_folder = "D:/Vs.code/AI_Anchor/backend/gemini/final_narratives"
    
    NARRATIVE_HISTORY = [] 
    
    print(f"\nğŸš€ [ç¨ç«‹æ¨¡å¼] Stage 2 (å‘å¾Œåˆä½µå¢å¼·ç‰ˆ) æ‰¹æ¬¡å•Ÿå‹•...")
    if os.path.exists(event_json_folder):
        files = sorted([f for f in os.listdir(event_json_folder) if f.endswith("_event.json")])
        for f in tqdm(files, desc="Processing"):
            base = f.replace("_event.json", "")
            vid_path = os.path.join(video_folder, f"{base}.mp4")
            json_path = os.path.join(event_json_folder, f)
            if os.path.exists(vid_path):
                res = process_single_video_stage2(vid_path, json_path, output_folder)
                if res: print(f"  -> Saved: {os.path.basename(res)}")
    else:
        print("âŒ æ‰¾ä¸åˆ° JSON è³‡æ–™å¤¾")