import os
import json
import re
from datetime import timedelta
from moviepy.editor import VideoFileClip
from vertexai.generative_models import Part
from haystack_integrations.components.generators.google_vertex import VertexAIGeminiGenerator
from haystack import component, Pipeline
from haystack.components.builders import PromptBuilder
from tqdm import tqdm

# ========== 1. è¨­å®šèˆ‡æ†‘è­‰ ==========
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
cred_path = os.path.join(PROJECT_ROOT, "credentials", "ai-anchor-462506-7887b7105f6a.json")
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = cred_path

# ========== 2. é—œéµåƒæ•¸ ==========
SYLLABLES_PER_SEC = 4.0      
MIN_EVENT_DURATION = 1.0      
MAX_RALLY_DURATION = 4.5
MIN_GAP_DURATION = 3.0        
MAX_INTRO_OUTRO_SYLLABLES = 30 
MERGE_THRESHOLD = 1.2 

# å…¨åŸŸæ­·å²ç´€éŒ„
NARRATIVE_HISTORY = [] 
HISTORY_WINDOW_SIZE = 3 

# ========== 3. å·¥å…·å‡½æ•¸ ==========
def seconds_to_timecode(seconds):
    m, s = divmod(seconds, 60)
    h, m = divmod(m, 60)
    return f"{int(h)}:{int(m):02d}:{s:04.1f}"

def format_duration(seconds):
    m = int(seconds // 60)
    s = seconds % 60
    return f"{m}:{s:04.1f}"

def parse_time_str(t_str):
    try:
        if not t_str: return 0.0
        parts = t_str.strip().split(':')
        sec = 0.0
        if len(parts) == 3: sec += float(parts[-3]) * 3600
        if len(parts) >= 2: sec += float(parts[-2]) * 60
        sec += float(parts[-1])
        return sec
    except: return 0.0

def estimate_speech_time(text):
    if not text: return 0.0
    chinese_chars = re.findall(r'[\u4e00-\u9fff]', text)
    text_no_zh = re.sub(r'[\u4e00-\u9fff]', ' ', text)
    text_clean_en = re.sub(r'[^\w\s]', '', text_no_zh)
    english_words = text_clean_en.split()
    count_punc = len(re.findall(r'[ï¼Œã€‚ï¼,.]', text))
    total_units = (len(chinese_chars) * 1.0) + (len(english_words) * 1.3) + (count_punc * 0.4)
    return total_units / SYLLABLES_PER_SEC

# ========== 4. Pipeline åˆå§‹åŒ– ==========
@component
class AddVideo2Prompt:
    @component.output_types(prompt=list)
    def run(self, uri: str, prompt: str):
        return {"prompt": [Part.from_uri(uri, mime_type="video/mp4"), prompt]}

@component
class GeminiGenerator:
    def __init__(self, project_id, location, model):
        self.project_id, self.location, self.model = project_id, location, model
    @component.output_types(replies=list)
    def run(self, prompt: list):
        generator = VertexAIGeminiGenerator(project_id=self.project_id, location=self.location, model=self.model)
        return {"replies": generator.run(prompt)["replies"]}

# ========== 5. Prompt æ¨¡æ¿ ==========
narrative_template = """ 
1. è§’è‰²è¨­å®š (Role)
ä½ æ˜¯ä¸€ä½**è³‡æ·±ã€ç†±è¡€ä¸”å…·å‚™æˆ°è¡“æ´å¯ŸåŠ›**çš„é ‚ç´šè³½äº‹ä¸»æ’­ã€‚
ä½ çš„ç›®æ¨™æ˜¯é€éè²éŸ³å°‡è§€çœ¾å¸¶å…¥è³½å ´ã€‚ä½ çš„è§£èªªé¢¨æ ¼ï¼š
- **æ‹’çµ•å¹³é‹ªç›´æ•˜**ï¼šä¸è¦ç•¶ã€Œå ±å¹•å“¡ã€ï¼Œè¦ç•¶ã€Œèªªæ›¸äººã€ã€‚
- **å¼·èª¿å› æœé—œä¿‚**ï¼šè§£é‡‹å‹•ä½œèƒŒå¾Œçš„æ„åœ–èˆ‡çµæœã€‚
- **å£èªåŒ– (TTS Friendly)**ï¼šä½¿ç”¨é©åˆæœ—è®€çš„çŸ­å¥ï¼Œé¿å…ç”Ÿç¡¬çš„æ›¸é¢ç”¨èªã€‚
- **æ³¨æ„ç´°ç¯€**ï¼šè«‹å–„ç”¨detailä¾†è±å¯Œæ–‡æœ¬è§£èªªã€‚

2. ä¸Šä¸‹æ–‡è³‡è¨Š (Context)
- **æ¯”è³½èƒŒæ™¯ (Static Info)**ï¼š
{{ intro }}
*(âš ï¸ é€™æ˜¯æœ¬å ´æ¯”è³½çš„æ ¸å¿ƒè³‡è¨Šï¼Œè«‹å‹™å¿…æ ¹æ“šæ­¤è¨­å®šä¾†ç¨±å‘¼çƒå“¡èˆ‡è¾¨è­˜èº«åˆ†)*

- **æ­·å²æˆ°æ³ (Flow)**ï¼š
{{ prev_context }}
*(è«‹ç¹¼æ‰¿ä¸Šè¿°çš„èªæ°£èˆ‡æƒ…ç·’)*

- **è¼¸å…¥ä¾†æº**ï¼šçµåˆ **JSON äº‹ä»¶éˆ** èˆ‡ **è¦–è¦ºç•«é¢** é€²è¡Œè§£èªªã€‚

3. ä»»å‹™åŸ·è¡Œ (Tasks)
ä½ çš„å·¥ä½œæ˜¯è¦å°‡ä¸€ç³»åˆ—çš„äº‹ä»¶è½‰åŒ–ç‚ºç”Ÿå‹•çš„è§£èªªæ–‡æœ¬ï¼š

- **ç‰¹æ®Šä»»å‹™æŒ‡å¼• (Special Tasks)**ï¼š
    - **[Summary]**: ç•¶çœ‹åˆ°æ­¤æ¨™è¨˜ï¼ˆå¦‚ `[Summary] é›™æ–¹é€£çºŒ 6 æ‹å¹³æŠ½`ï¼‰ï¼Œ**è«‹å‹¿é€ä¸€æè¿°å‹•ä½œ**ã€‚è«‹ç›´æ¥ç”¨ä¸€å¥è©±ç¸½çµæˆ°æ³ï¼Œä¾‹å¦‚ï¼šã€Œé›™æ–¹åœ¨ç¶²å‰å±•é–‹äº†ä»¤äººçª’æ¯çš„å¿«é€Ÿå°æ”»ï¼ã€
    - **[Intro]**: å½±ç‰‡å‰›é–‹å§‹ã€‚è«‹ç°¡å–®é–‹å ´ï¼Œä»‹ç´¹é¸æ‰‹æˆ–ç•¶å‰æ¯”åˆ†å±€å‹¢ã€‚
    - **[Gap]**: æ¯”è³½é–“éš™ã€‚è«‹æè¿°çƒå“¡çš„å¿ƒç†ç‹€æ…‹ã€æ“¦æ±—ã€æ›çƒã€èª¿æ•´å‘¼å¸ã€‚
    - **[Outro]**: å½±ç‰‡çµæŸã€‚è«‹å¿«é€Ÿç¸½çµå‰›å‰›é€™çƒçš„çµæœã€å¾—åˆ†è€…ã€‚
    - **[Replay]**: ç²¾å½©å›æ”¾/æ…¢å‹•ä½œã€‚è«‹**æ·±å…¥åˆ†æ**å‰›æ‰å‹•ä½œçš„æŠ€è¡“ç´°ç¯€ï¼Œèªæ°£å°ˆæ¥­ä¸”å¸¶æœ‰è®šå˜†ã€‚

4. åš´æ ¼ç¦ä»¤ (Strict Prohibitions)
â›”ï¸ **é•è¦å°‡å°è‡´ç³»çµ±éŒ¯èª¤ï¼š**
- **ğŸˆ² ç¦æ­¢æµæ°´å¸³**ï¼šçµ•å°ä¸è¦ä½¿ç”¨ã€Œç„¶å¾Œ...æ¥è‘—...ã€ã€‚è«‹ç”¨**å› æœé—œä¿‚**ä¸²è¯ã€‚
- **ğŸˆ² ç¦æ­¢é–“éš™å¹»è¦º**ï¼šåœ¨ `[Gap]` çµ•å°ä¸èƒ½æè¿°æ–°çš„æ“Šçƒå‹•ä½œã€‚åªèƒ½è¬›è©•è«–ã€‚
- **ğŸˆ² ç¦æ­¢æœªåœå…ˆçŸ¥**ï¼šè‹¥ `[Score]` æœªå‡ºç¾ï¼Œä¸å¯æå‰å®£å‘Šå¾—åˆ†ã€‚
- **ğŸˆ² åš´æ ¼å­—æ•¸æ§åˆ¶**ï¼š`constraint` æ˜¯ç‰©ç†é™åˆ¶ã€‚**å¯§å¯è©±å°‘ç²¾ç°¡ï¼Œçµ•ä¸è¶…æ™‚çˆ†éŸ³ã€‚**

5. è¼¸å‡ºæ ¼å¼
è¼¸å‡ºç´” JSON é™£åˆ—ï¼ŒåŒ…å« `id` å’Œ `text` å…©å€‹æ¬„ä½ã€‚

6. ç¯„ä¾‹ (Example)
**è¼¸å…¥:**
[
    {"id": 0, "constraint": "é™ 14 éŸ³ç¯€", "content": "[Serve] æˆ´è³‡ç© - ç™¼çƒ (éé«˜) -> [Offense] é™³é›¨è² - æ’²çƒ (ä¸‹å£“)"},
    {"id": 1, "constraint": "é™ 8 éŸ³ç¯€", "content": "[Score] ç„¡ - ç•Œå…§å¾—åˆ†"}
]
**è¼¸å‡º:**
[
    {"id": 0, "text": "å°æˆ´é€™çƒç™¼é«˜äº†ï¼é™³é›¨è²æ²’æ”¾éæ©Ÿæœƒç›´æ¥ä¸‹å£“ï¼"},
    {"id": 1, "text": "è½åœ°å¾—åˆ†ï¼é€™çƒæŠ“å¾—å¤ªæº–äº†ï¼"}
]

ğŸ“Š **å¾…è™•ç†æ•¸æ“šï¼š**
{{ event_data }}

è«‹è¼¸å‡º JSONï¼š
"""

# ğŸ”¥ [ä¿®æ­£] å¿…é ˆåŒ…å« "intro"ï¼Œå¦å‰‡æœƒå ± Input not found éŒ¯èª¤
prompt_builder = PromptBuilder(template=narrative_template, required_variables=["event_data", "prev_context", "intro"])

add_video_s2 = AddVideo2Prompt()
gemini_s2 = GeminiGenerator(project_id="ai-anchor-462506", location="us-central1", model="gemini-2.5-flash")

pipeline_s2 = Pipeline()
pipeline_s2.add_component(instance=prompt_builder, name="prompt_builder")
pipeline_s2.add_component(instance=add_video_s2, name="add_video")
pipeline_s2.add_component(instance=gemini_s2, name="llm")
pipeline_s2.connect("prompt_builder.prompt", "add_video.prompt")
pipeline_s2.connect("add_video.prompt", "llm.prompt")


# ========== 7. æ ¸å¿ƒåŠŸèƒ½ï¼šè™•ç†å–®ä¸€å½±ç‰‡ (æœ€çµ‚å®Œæ•´ç‰ˆ) ==========
def process_single_video_stage2(video_path, event_json_path, output_folder):
    global NARRATIVE_HISTORY

    os.makedirs(output_folder, exist_ok=True)
    base_name = os.path.splitext(os.path.basename(video_path))[0]
    
    # 0. åŸºç¤è³‡è¨Šè®€å–
    try:
        with VideoFileClip(video_path) as clip: total_duration = clip.duration
    except: total_duration = 30.0 

    try:
        with open(event_json_path, 'r', encoding='utf-8') as f: 
            data = json.load(f)
            events = data.get("events", [])
            video_uri = data.get("video_uri", "") or data.get("segment_video_uri", "")
            # ğŸ”¥ è®€å– introï¼Œè§£æ±ºèº«åˆ†å¤±æ†¶å•é¡Œ
            current_intro = data.get("intro", "é€™æ˜¯ä¸€å ´ç²¾å½©çš„ç¾½çƒæ¯”è³½ï¼Œè«‹æ ¹æ“šç•«é¢è§£èªªã€‚")
    except Exception as e:
        print(f"âŒ è®€å– JSON å¤±æ•—: {e}")
        return None

    if not events: return None

    # ==========================================
    # Phase 1: äº‹ä»¶èšåˆ (èªæ„æ„ŸçŸ¥ + æ‘˜è¦å¢å¼·ç‰ˆ)
    # ==========================================
    narrative_blocks = []
    current_block_events = []
    current_block_cats = [] 
    block_start_raw = 0.0
    
    events.sort(key=lambda x: parse_time_str(x.get("start_time", "0:00")))
    last_event_end = 0.0
    
    for i, event in enumerate(events):
        start = parse_time_str(event.get("start_time"))
        if start > total_duration - 0.5: continue

        end = parse_time_str(event.get("end_time"))
        if end == 0.0: end = start + 1.0
        
        cat = event.get("category", "General")
        sub = event.get("subject") or event.get("player", "çƒå“¡")
        act = event.get("action", "")
        det = event.get("detail", "")
        event_str = f"[{cat}] {sub} - {act} ({det})"

        # --- åˆ‡åˆ†é‚è¼¯ ---
        should_split = False
        gap_from_last = start - last_event_end
        current_dur = end - block_start_raw
        
        # ç¡¬æ€§æ¢ä»¶
        if not current_block_events:
            should_split = False
        elif cat == "Serve" or cat == "Start":
            should_split = True # ç™¼çƒå¿…æ–·
        elif "Score" in current_block_cats: 
            should_split = True # å¾—åˆ†å¾Œå¿…æ–·
        elif gap_from_last > 2.0:
            should_split = True # é–“éš”éé•·å¿…æ–·
        
        # è»Ÿæ€§æ¢ä»¶
        elif not should_split:
            is_combo = (current_block_cats and current_block_cats[-1] == "Offense" and cat == "Defense")
            if not is_combo and current_dur > 4.5:
                should_split = True
            elif len(current_block_events) >= 5:
                should_split = True
        
        if should_split:
            # ğŸ”¥ [æ‘˜è¦æ©Ÿåˆ¶] æª¢æŸ¥æ˜¯å¦éœ€è¦ Summary
            final_content = " -> ".join(current_block_events)
            
            exch_count = current_block_cats.count("Exchange")
            drive_count = sum(1 for s in current_block_events if "å¹³æŠ½" in s or "æ“‹" in s)
            total_count = len(current_block_events)
            
            if total_count >= 3 and (exch_count + drive_count) >= (total_count * 0.7):
                final_content = f"[Summary] é›™æ–¹é€²è¡Œäº† {total_count} æ‹çš„å¿«é€Ÿå¹³æŠ½æ“‹/ä¾†å›å°å³™"
            
            narrative_blocks.append({
                "type": "RALLY",
                "raw_start": block_start_raw,
                "raw_end": last_event_end,
                "content": final_content
            })
            
            current_block_events = [event_str]
            current_block_cats = [cat]
            block_start_raw = start
        else:
            current_block_events.append(event_str)
            current_block_cats.append(cat)
            if len(current_block_events) == 1: block_start_raw = start
        
        last_event_end = max(last_event_end, end)

    # è™•ç†æ®˜ç•™ Block
    if current_block_events:
        final_content = " -> ".join(current_block_events)
        exch_count = current_block_cats.count("Exchange")
        if len(current_block_events) >= 3 and exch_count >= len(current_block_events)*0.7:
             final_content = f"[Summary] é›™æ–¹é€²è¡Œäº†é€£çºŒçš„ä¾†å›å°å³™"

        narrative_blocks.append({
            "type": "RALLY",
            "raw_start": block_start_raw,
            "raw_end": last_event_end,
            "content": final_content
        })

    # ==========================================
    # Phase 2: é å…ˆæ’ç¨‹ (å«åæ‡‰å»¶é² + æ™ºæ…§éŸ³ç¯€)
    # ==========================================
    scheduled_tasks = [] 
    audio_cursor = 0.0 
    
    # ğŸ”¥ åæ‡‰å»¶é²è¨­å®š
    DELAY_MAP = {
        "setup": 2.0, "serve": 2.0, "offense": 0.6, "smash": 0.5,    
        "defense": 0.7, "score": 0.1, "gap": 0.0, "intro": 0.0, "outro": 0.0, "default": 0.8   
    }

    # 1. Intro å¡«ç©º
    first_block_start = narrative_blocks[0]["raw_start"] if narrative_blocks else total_duration
    if first_block_start > 3.0:
        intro_dur = min(first_block_start - 0.5, 6.0)
        intro_limit = max(int(intro_dur * SYLLABLES_PER_SEC), 10)
        
        scheduled_tasks.append({
            "id": "intro",
            "final_start": 0.0,
            "final_end": intro_dur,
            "duration": intro_dur,
            "type": "INTRO",
            "raw_content": "é–‹å ´",
            "prompt_constraint": f"é™ {intro_limit} éŸ³ç¯€",
            "prompt_content": "[Intro] é€™æ˜¯æ¯”è³½é–‹å§‹ï¼Œè«‹åšç°¡å–®é–‹å ´ä»‹ç´¹ã€‚"
        })
        audio_cursor = intro_dur

    # 2. è¿´åœˆæ’ç¨‹
    for idx, block in enumerate(narrative_blocks):
        delay = 0.8
        content_lower = block["content"].lower()
        for k, v in DELAY_MAP.items():
            if k in content_lower: delay = v; break
        ideal_start = block["raw_start"] + delay
        
        # Gap å¡«ç©º
        gap_duration = ideal_start - audio_cursor
        if gap_duration > 4.0:
            fill_dur = min(gap_duration - 0.5, 5.0)
            gap_start = audio_cursor + 0.2
            gap_limit = max(int(fill_dur * SYLLABLES_PER_SEC), 8)

            scheduled_tasks.append({
                "id": f"gap_{idx}",
                "final_start": gap_start,
                "final_end": gap_start + fill_dur,
                "duration": fill_dur,
                "type": "GAP",
                "raw_content": "é–“éš™",
                "prompt_constraint": f"é™ {gap_limit} éŸ³ç¯€",
                "prompt_content": "[Gap] å¡«è£œç©ºç™½ï¼Œæè¿°çƒå“¡ç‹€æ…‹æˆ–å¿ƒç†ã€‚"
            })
            audio_cursor = gap_start + fill_dur

        # æ’ç¨‹ç•¶å‰ Block
        start_time = max(ideal_start, audio_cursor + 0.2)
        
        raw_span = block["raw_end"] - block["raw_start"]
        base_min_duration = 3.5 
        target_dur = min(raw_span + 2.0, 6.0) 
        target_dur = max(target_dur, base_min_duration) 

        # Lookahead
        if idx < len(narrative_blocks) - 1:
            next_raw_start = narrative_blocks[idx+1]["raw_start"]
            deadline = next_raw_start + 1.0
            max_allowed_dur = max(1.5, deadline - start_time)
            target_dur = min(target_dur, max_allowed_dur)

        end_time = start_time + target_dur
        if end_time > total_duration: end_time = total_duration
        
        final_duration = end_time - start_time
        if final_duration < 0.8: continue

        # ğŸ”¥ æ™ºæ…§éŸ³ç¯€è¨ˆç®—
        syllable_count = int(final_duration * SYLLABLES_PER_SEC)
        
        is_crucial = any(k in content_lower for k in ["score", "smash", "kill", "won"])
        is_summary = "[summary]" in content_lower
        
        if is_crucial or is_summary:
            syllable_count = max(syllable_count, 12) 
        else:
            syllable_count = max(syllable_count, 5)

        scheduled_tasks.append({
            "id": idx,
            "final_start": start_time,
            "final_end": end_time,
            "duration": final_duration,
            "type": block["type"],
            "raw_content": block["content"],
            "prompt_constraint": f"é™ {syllable_count} éŸ³ç¯€",
            "prompt_content": block["content"]
        })
        audio_cursor = end_time

    # 3. Outro/Replay è™•ç†
    remaining_time = total_duration - audio_cursor
    if remaining_time > 12.0:
        outro_dur = 5.0
        scheduled_tasks.append({
            "id": "outro_summary",
            "final_start": audio_cursor + 0.2,
            "final_end": audio_cursor + 0.2 + outro_dur,
            "duration": outro_dur,
            "type": "OUTRO",
            "raw_content": "çµå°¾ç¸½çµ",
            "prompt_constraint": f"é™ {int(outro_dur * SYLLABLES_PER_SEC)} éŸ³ç¯€",
            "prompt_content": "[Outro] æœ¬å›åˆçµæŸï¼Œå¿«é€Ÿç¸½çµå¾—åˆ†é—œéµã€‚"
        })
        audio_cursor += (0.2 + outro_dur)
        replay_dur = min(remaining_time - outro_dur - 1.0, 8.0) 
        if replay_dur > 3.0:
            scheduled_tasks.append({
                "id": "outro_replay",
                "final_start": audio_cursor + 0.5,
                "final_end": audio_cursor + 0.5 + replay_dur,
                "duration": replay_dur,
                "type": "REPLAY",
                "raw_content": "æ…¢å‹•ä½œåˆ†æ",
                "prompt_constraint": f"é™ {max(int(replay_dur * SYLLABLES_PER_SEC), 10)} éŸ³ç¯€",
                "prompt_content": "[Replay] é€™æ˜¯ç²¾å½©é‡æ’­ç•«é¢ï¼Œè«‹æ·±å…¥åˆ†ææŠ€è¡“ç´°ç¯€ã€‚"
            })
    elif remaining_time > 3.0:
        outro_dur = min(remaining_time - 0.5, 6.0)
        scheduled_tasks.append({
            "id": "outro",
            "final_start": audio_cursor + 0.2,
            "final_end": audio_cursor + 0.2 + outro_dur,
            "duration": outro_dur,
            "type": "OUTRO",
            "raw_content": "çµå°¾",
            "prompt_constraint": f"é™ {max(int(outro_dur * SYLLABLES_PER_SEC), 8)} éŸ³ç¯€",
            "prompt_content": "[Outro] æœ¬å›åˆçµæŸï¼Œç¸½çµå‰›æ‰çš„ç²¾å½©è¡¨ç¾ã€‚"
        })

    if not scheduled_tasks: return None

    # ==========================================
    # Phase 3: ç”Ÿæˆè§£èªª (Generation) - å¸¶ Context & Intro
    # ==========================================
    llm_input_data = []
    for task in scheduled_tasks:
        llm_input_data.append({
            "id": task["id"],
            "constraint": task["prompt_constraint"], 
            "content": task["prompt_content"]
        })
        
    if NARRATIVE_HISTORY:
        recent_history = NARRATIVE_HISTORY[-HISTORY_WINDOW_SIZE:]
        history_str = "\n".join([f"- {h}" for h in recent_history])
    else:
        history_str = "é€™æ˜¯æ¯”è³½çš„ç¬¬ä¸€å€‹ç‰‡æ®µï¼Œè«‹ç›´æ¥é–‹å§‹è§£èªªã€‚"

    try:
        # ğŸ”¥ å‚³å…¥ intro åˆ° Pipeline
        res = pipeline_s2.run({
            "add_video": {"uri": video_uri},
            "prompt_builder": {
                "event_data": json.dumps(llm_input_data, ensure_ascii=False, indent=2),
                "prev_context": history_str,
                "intro": current_intro 
            }
        })
        reply = res["llm"]["replies"][0].strip()
        if "```" in reply:
            match = re.search(r'\[.*\]', reply, re.DOTALL)
            if match: reply = match.group()
        generated_list = json.loads(reply)
        generated_map = {str(item["id"]): item["text"] for item in generated_list}
    except Exception as e:
        print(f"âŒ [Stage 2 LLM éŒ¯èª¤] {e}")
        return None

    # ==========================================
    # Phase 4: è¼¸å‡ºçµ„è£ (Assembly) - åš´æ ¼æ’è»¸ + é›™é‡æª¢æŸ¥
    # ==========================================
    commentary = []
    segment_texts = []
    num_tasks = len(scheduled_tasks)

    for i, task in enumerate(scheduled_tasks):
        tid = str(task["id"])
        text = generated_map.get(tid, "")
        if not text: continue
        
        final_start = task["final_start"]
        
        # ç¡¬æ€§æˆªæ­¢
        if i < num_tasks - 1:
            next_start = scheduled_tasks[i+1]["final_start"]
            hard_limit_end = next_start - 0.2 
        else:
            hard_limit_end = total_duration
            
        # ğŸ”¥ é›™é‡æª¢æŸ¥
        estimated_dur = estimate_speech_time(text)
        calculated_end = final_start + estimated_dur
        final_end = min(calculated_end, hard_limit_end)
        
        if final_end <= final_start: final_end = final_start + 0.5 
        final_dur = final_end - final_start

        if final_dur > 0.1:
            speed_val = estimated_dur / final_dur
        else:
            speed_val = 1.0

        # é™åˆ¶ç¯„åœï¼šæœ€æ…¢ 1.0å€ï¼Œæœ€å¿« 2.0å€
        speed_val = round(max(1.0,min(speed_val,2.0)),2)

        # æƒ…ç·’åˆ¤æ–·
        emotion = "å¹³ç©©" 
        content_lower = task["raw_content"].lower()
        task_type = task["type"]
        
        if task_type == "INTRO": emotion = "èˆ’ç·©"
        elif task_type == "OUTRO": emotion = "æ¿€å‹•" 
        elif task_type == "REPLAY": emotion = "å°ˆæ¥­"       
        elif task_type == "GAP": emotion = "èˆ’ç·©"
        elif any(k in content_lower for k in ["score", "smash", "kill", "won", "winner"]): emotion = "æ¿€å‹•"
        elif any(k in content_lower for k in ["defense", "save", "foul", "out", "mistake"]): emotion = "ç·Šå¼µ"
        elif any(k in content_lower for k in ["serve", "prepare"]): emotion = "èˆ’ç·©"
        elif any(k in content_lower for k in ["miss", "error", "fail"]): emotion = "éºæ†¾"

        commentary.append({
            "start_time": seconds_to_timecode(final_start),
            "end_time": seconds_to_timecode(final_end),
            "time_range": format_duration(final_dur),
            "speed": speed_val,
            "emotion": emotion,
            "text": text
        })
        segment_texts.append(text)

    if segment_texts:
        NARRATIVE_HISTORY.append(" ".join(segment_texts))
        if len(NARRATIVE_HISTORY) > 10: NARRATIVE_HISTORY.pop(0)

    output_path = os.path.join(output_folder, f"{base_name}.json")
    if commentary:
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump({"segment": base_name, "commentary": commentary}, f, ensure_ascii=False, indent=2)
        return output_path
    else:
        return None

# ========== 8. ç¨ç«‹é‹è¡Œæ¨¡å¼ ==========
if __name__ == "__main__":
    video_folder = "D:/Vs.code/AI_Anchor/backend/video_splitter/badminton_segments"
    event_json_folder = "D:/Vs.code/AI_Anchor/backend/gemini/event_analysis_output"
    output_folder = "D:/Vs.code/AI_Anchor/backend/gemini/final_narratives"
    
    NARRATIVE_HISTORY = [] 
    
    print(f"\nğŸš€ [ç¨ç«‹æ¨¡å¼] Stage 2 (æœ€çµ‚å®Œç¾ç‰ˆ) æ‰¹æ¬¡å•Ÿå‹•...")
    if os.path.exists(event_json_folder):
        files = sorted([f for f in os.listdir(event_json_folder) if f.endswith("_event.json")])
        for f in tqdm(files, desc="Processing"):
            base = f.replace("_event.json", "")
            vid_path = os.path.join(video_folder, f"{base}.mp4")
            json_path = os.path.join(event_json_folder, f)
            if os.path.exists(vid_path):
                res = process_single_video_stage2(vid_path, json_path, output_folder)
                if res: print(f"  -> Saved: {os.path.basename(res)}")
    else:
        print("âŒ æ‰¾ä¸åˆ° JSON è³‡æ–™å¤¾")