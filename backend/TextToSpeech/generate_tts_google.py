import os
import json
import re
from google.cloud import texttospeech
import hashlib

# ========== æ†‘è­‰è¼‰å…¥ã€è¨­å®š ==========
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
cred_path = os.path.join(os.path.dirname(PROJECT_ROOT), "credentials", "ai-anchor-462506-7887b7105f6a.json")
assert os.path.exists(cred_path), f"âŒ æ†‘è­‰ä¸å­˜åœ¨: {cred_path}"
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = cred_path


client = texttospeech.TextToSpeechClient()

# ========== åƒæ•¸è¨­å®š ==========
# å…¨åŸŸé è¨­èªé€Ÿ (ç•¶ JSON è£¡æ²’æœ‰ speed æ™‚çš„å‚™æ¡ˆ)
# é«”è‚²è§£èªªé€šå¸¸æ¯”æœ—è®€å¿«ï¼Œå»ºè­°è¨­ 1.2 å·¦å³
GLOBAL_DEFAULT_RATE = 1.2

# æƒ…ç·’åˆ°èªé€Ÿ(rate)å’ŒéŸ³é‡(volume_gain_db)çš„æ˜ å°„
EMOTION_TTS_PARAMS = {
    "å¹³ç©©": {"volume_gain_db": 0.0},
    
    # === é«˜å¼µåŠ› (å¤§è²) ===
    "æ¿€å‹•": {"volume_gain_db": 3.5},   # å¾ˆå¤§è²
    "ç·Šå¼µ": {"volume_gain_db": 2.0},   # ç¨å¤§è²
    "ç²¾å½©": {"volume_gain_db": 3.0},   # å¾ˆå¤§è²
    "å¼·èª¿": {"volume_gain_db": 2.5},   # ç¨å¤§è²

    # === ä½å¼µåŠ› (å°ˆæ¥­/æŸ”å’Œ) ===
    "å°ˆæ¥­": {"volume_gain_db": 1.0},   # æ¬Šå¨æ„Ÿï¼Œç¨å¤§è²
    "èˆ’ç·©": {"volume_gain_db": 0.0},   # æ­£å¸¸
    "éºæ†¾": {"volume_gain_db": -2.0},  # å°è²
    "ç–‘å•": {"volume_gain_db": 1.5},   # ç¨å¾®æé«˜éŸ³é‡ä»¥ç¤ºç–‘å•
}

def clean_emotion_tag(text):
    m = re.match(r"ã€(.+?)ã€‘(.*)", text)
    if m:
        return m.group(1), m.group(2).strip()
    else:
        return "å¹³ç©©", text  # æ²’æ¨™ç±¤å°±ç•¶å¹³ç©©

def synthesize_sentence(sentence_text, emotion, output_path, custom_speed=None, voice="cmn-TW-Wavenet-A"):
    # 1. å–å¾—æƒ…ç·’åƒæ•¸ (åªæ‹¿éŸ³é‡)
    params = EMOTION_TTS_PARAMS.get(emotion, EMOTION_TTS_PARAMS["å¹³ç©©"])
    volume_db = params["volume_gain_db"]
    
    # 2. æ±ºå®šèªé€Ÿ (Rate) - å¾¹åº•è§£è€¦é‚è¼¯
    # å„ªå…ˆæ¬Šï¼šJSON æŒ‡å®šå€¼ > å…¨åŸŸé è¨­å€¼
    if custom_speed is not None and float(custom_speed) > 0:
        raw_rate = float(custom_speed)
        # åŠ ä¸Šå®‰å…¨é™åˆ¶ (0.75 ~ 2.0) é˜²æ­¢æ¥µç«¯å€¼
        final_rate = max(0.75, min(raw_rate, 2.0))
        # print(f"   âš¡ [Stage2æ§åˆ¶] èªé€Ÿ: {final_rate}") 
    else:
        final_rate = GLOBAL_DEFAULT_RATE
        # print(f"   âš“ [å…¨åŸŸé è¨­] èªé€Ÿ: {final_rate}")

    # 3. å‹•æ…‹åœé “ (èªé€Ÿè¶Šå¿«ï¼Œæ¨™é»åœé “è¶ŠçŸ­)
    pause_scale = 1.0 / max(final_rate, 0.8)
    
    ssml_text = sentence_text
    ssml_text = ssml_text.replace("ï¼Œ", f"<break time='{int(200*pause_scale)}ms'/>")
    ssml_text = ssml_text.replace("ã€", f"<break time='{int(100*pause_scale)}ms'/>")
    ssml_text = ssml_text.replace("ã€‚", f"<break time='{int(400*pause_scale)}ms'/>")
    ssml_text = ssml_text.replace("ï¼", f"<break time='{int(500*pause_scale)}ms'/>")
    
    # 4. çµ„åˆ SSML (Rate ä¾†è‡ªè®Šæ•¸, Volume ä¾†è‡ªæƒ…ç·’è¡¨)
    ssml = f"<speak><prosody rate='{final_rate}' volume='{volume_db}dB'>{ssml_text}</prosody></speak>"

    synthesis_input = texttospeech.SynthesisInput(ssml=ssml)
    voice_params = texttospeech.VoiceSelectionParams(
        language_code="cmn-TW",
        name=voice,
        ssml_gender=texttospeech.SsmlVoiceGender.FEMALE,
    )
    audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)

    try:
        response = client.synthesize_speech(
            input=synthesis_input,
            voice=voice_params,
            audio_config=audio_config,
        )
        with open(output_path, "wb") as f:
            f.write(response.audio_content)
        
        # Log é¡¯ç¤ºç¾åœ¨çš„ç‹€æ³
        print(f"âœ… ç”Ÿæˆ: {emotion} | ğŸ”Š {volume_db}dB | â© x{final_rate}")
        return {"status": "success", "output": output_path, "emotion": emotion}
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¤±æ•—: {e}")
        return {"status": "error", "message": str(e), "output": output_path}

def process_segment_json(json_path, output_base_dir):
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    segment_name_raw = data.get("segment", os.path.splitext(os.path.basename(json_path))[0])
    segment_name = segment_name_raw.replace(".mp4", "")
    commentary = data.get("commentary", [])

    if not commentary:
        msg = f"âš ï¸ ç©ºæ—ç™½ï¼Œè·³éï¼š{segment_name}"
        print(msg)
        return {"status": "warning", "message": msg, "segment": segment_name}

    segment_dir = os.path.join(output_base_dir, segment_name)
    os.makedirs(segment_dir, exist_ok=True)

    results = []
    seen_texts = set()
    for idx, item in enumerate(commentary):
        # <<<< ä¿®æ­£é»ï¼šç›´æ¥è®€å–ç¨ç«‹çš„ emotion æ¬„ä½ >>>>
        text = item["text"]
        emotion = item.get("emotion", "å¹³ç©©") # å¦‚æœæ²’æœ‰ emotion æ¬„ä½ï¼Œé è¨­ç‚ºå¹³ç©©
        speed_val = item.get("speed")

        # 1. è¨ˆç®—ç•¶å‰æ–‡æœ¬çš„ SHA256 é›œæ¹Šå€¼
        # ğŸ‘‡ ä¿®æ”¹ï¼šå°‡ speed ä¹ŸåŠ å…¥ hash è¨ˆç®—ï¼Œç¢ºä¿é€Ÿåº¦è®Šæ›´æ™‚æœƒé‡ç”¢
        hash_content = f"{text}|{emotion}|{speed_val}"
        text_hash = hashlib.sha256(hash_content.encode('utf-8')).hexdigest()
        
        # 2. å®šç¾© MP3 æª”æ¡ˆå’Œä¼´éš¨çš„é›œæ¹Šæª”æ¡ˆè·¯å¾‘
        out_path_mp3 = os.path.join(segment_dir, f"{idx+1:03d}_{emotion}.mp3")
        out_path_hash = os.path.join(segment_dir, f"{idx+1:03d}_{emotion}.hash")

        # 3. æª¢æŸ¥è·³éæ¢ä»¶ (åªæœ‰ MP3 å’Œ Hash æ–‡ä»¶éƒ½å­˜åœ¨ä¸”é›œæ¹ŠåŒ¹é…æ™‚æ‰è·³é)
        is_mp3_present = os.path.exists(out_path_mp3)
        is_hash_present = os.path.exists(out_path_hash)

        should_regenerate = True
        
        if is_mp3_present and is_hash_present:
            with open(out_path_hash, 'r', encoding='utf-8') as hf:
                stored_hash = hf.read().strip()
            
            if stored_hash == text_hash:
                print(f"âœ… èªéŸ³å·²å­˜åœ¨ä¸”æ–‡æœ¬æœªä¿®æ”¹ï¼Œè·³éç”Ÿæˆï¼š{out_path_mp3}")
                should_regenerate = False
            else:
                print(f"âš ï¸ æ–‡æœ¬å·²ä¿®æ”¹ï¼Œéœ€è¦é‡æ–°ç”ŸæˆèªéŸ³ï¼š{out_path_mp3}")
        
        if not should_regenerate:
            continue # è·³é TTS API å‘¼å«

        # 4. åŸæœ‰çš„é‡è¤‡æ–‡æœ¬æª¢æŸ¥ (é˜²æ­¢åŒä¸€ JSON å…§é‡è¤‡ç”Ÿæˆ)
        if text in seen_texts:
            print(f"âš ï¸ é‡è¤‡æ—ç™½ï¼Œè·³éï¼š{text}")
            continue

        seen_texts.add(text)
        
        # 5. åŸ·è¡ŒèªéŸ³ç”Ÿæˆ (å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–é›œæ¹Šä¸åŒ¹é…)
        res = synthesize_sentence(text, emotion, out_path_mp3, custom_speed=speed_val)
        
        # 6. å¦‚æœç”ŸæˆæˆåŠŸï¼Œå„²å­˜æ–°çš„é›œæ¹Šå€¼åˆ° .hash æª”æ¡ˆ
        if res['status'] == 'success':
            with open(out_path_hash, 'w', encoding='utf-8') as hf:
                hf.write(text_hash)
            
        results.append(res)

    return {"status": "success", "segment": segment_name, "results": results}

def batch_process(input_json_folder, output_folder):
    os.makedirs(output_folder, exist_ok=True)
    json_files = [f for f in os.listdir(input_json_folder) if f.endswith(".json")]

    all_results = []
    for jf in sorted(json_files):
        json_path = os.path.join(input_json_folder, jf)
        res = process_segment_json(json_path, output_folder)
        all_results.append(res)

    return {"status": "success", "processed_files": len(json_files), "details": all_results}

# âœ… å¾Œç«¯å–®æ¸¬æ¨¡å¼
if __name__ == "__main__":
    input_folder = "D:/Vs.code/AI_Anchor/backend/gemini/final_narratives"
    output_folder = "D:/Vs.code/AI_Anchor/backend/TextToSpeech/final_tts_google"
    result = batch_process(input_folder, output_folder)
    print(json.dumps(result, ensure_ascii=False, indent=2))
