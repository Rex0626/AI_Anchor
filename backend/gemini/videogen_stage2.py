import os
import json
import re
from datetime import timedelta
from moviepy.editor import VideoFileClip
from vertexai.generative_models import Part
from haystack_integrations.components.generators.google_vertex import VertexAIGeminiGenerator
from haystack import component, Pipeline
from haystack.components.builders import PromptBuilder
from tqdm import tqdm

# ========== 1. è¨­å®šèˆ‡æ†‘è­‰ ==========
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
cred_path = os.path.join(PROJECT_ROOT, "credentials", "ai-anchor-462506-7887b7105f6a.json")
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = cred_path

# ========== 2. é—œéµåƒæ•¸ ==========
SYLLABLES_PER_SEC = 4.8       
MIN_EVENT_DURATION = 1.0      
MAX_RALLY_DURATION = 6.0      
MAX_INTRO_OUTRO_SYLLABLES = 30 

# ========== 3. å·¥å…·å‡½æ•¸ ==========
def seconds_to_timecode(seconds):
    m, s = divmod(seconds, 60)
    h, m = divmod(m, 60)
    return f"{int(h)}:{int(m):02d}:{s:04.1f}"

def format_duration(seconds):
    m = int(seconds // 60)
    s = seconds % 60
    return f"{m}:{s:04.1f}"

def parse_time_str(t_str):
    try:
        if not t_str: return 0.0
        parts = t_str.strip().split(':')
        sec = 0.0
        if len(parts) == 3: sec += float(parts[-3]) * 3600
        if len(parts) >= 2: sec += float(parts[-2]) * 60
        sec += float(parts[-1])
        return sec
    except: return 0.0

def estimate_speech_time(text):
    if not text: return 0.0
    chinese_chars = re.findall(r'[\u4e00-\u9fff]', text)
    text_no_zh = re.sub(r'[\u4e00-\u9fff]', ' ', text)
    text_clean_en = re.sub(r'[^\w\s]', '', text_no_zh)
    english_words = text_clean_en.split()
    count_punc = len(re.findall(r'[ï¼Œã€‚ï¼,.]', text))
    total_units = (len(chinese_chars) * 1.0) + (len(english_words) * 1.3) + (count_punc * 0.4)
    return total_units / SYLLABLES_PER_SEC

# ========== 4. Pipeline åˆå§‹åŒ– (å…¨åŸŸ) ==========
@component
class AddVideo2Prompt:
    @component.output_types(prompt=list)
    def run(self, uri: str, prompt: str):
        return {"prompt": [Part.from_uri(uri, mime_type="video/mp4"), prompt]}

@component
class GeminiGenerator:
    def __init__(self, project_id, location, model):
        self.project_id, self.location, self.model = project_id, location, model
    @component.output_types(replies=list)
    def run(self, prompt: list):
        generator = VertexAIGeminiGenerator(project_id=self.project_id, location=self.location, model=self.model)
        return {"replies": generator.run(prompt)["replies"]}

# ========== 5. Prompt æ¨¡æ¿ (æ•¸æ“š + è¦–è¦ºé›™é‡é©…å‹•) ==========
narrative_template = """ 
ä½ æ˜¯ä¸€ä½**è³‡æ·±ã€ç¯€å¥æ˜å¿«**çš„ç¾½çƒè³½äº‹å³æ™‚ä¸»æ’­ã€‚
ç¾åœ¨ä½ æœ‰å…©å€‹è³‡è¨Šä¾†æºï¼š
1.  **æ¯”è³½å½±ç‰‡**ï¼šè«‹è§€å¯Ÿç•«é¢ä¸­çš„ç²¾å½©ç´°ç¯€ã€çƒå“¡æƒ…ç·’èˆ‡æ“ŠçƒåŠ›é“ã€‚
2.  **æ™‚é–“å€å¡Šåˆ—è¡¨ (JSON)**ï¼šé€™æ˜¯ç²¾æº–çš„å‹•ä½œç´€éŒ„èˆ‡éŸ³ç¯€é™åˆ¶ã€‚

ğŸ¯ **ä½ çš„ä»»å‹™ï¼šè¦–è¦ºèˆ‡æ•¸æ“šçš„å®Œç¾çµåˆ**
è«‹æ ¹æ“š JSON çš„æŒ‡å¼•é–å®šæ™‚é–“æ®µï¼Œä¸¦**è§€çœ‹å½±ç‰‡**ä¾†è±å¯Œä½ çš„è§£èªªã€‚

**å…«å¤§é»ƒé‡‘è¦å‰‡ (è«‹åš´æ ¼éµå®ˆ)ï¼š**
1.  **æ¥µç°¡é¢¨æ ¼**ï¼šä½¿ç”¨ã€Œçƒå“¡+å‹•ä½œã€çš„çŸ­èªæ¨¡å¼ (å¦‚ï¼šMiyauæŒ‘é«˜ã€Tanæ®ºçƒ)ã€‚
2.  **è³‡æ–™æ­£ç¢ºæ€§ (é‡è¦)**ï¼šäººåèˆ‡å‹•ä½œé¡å‹**å¿…é ˆç›´æ¥ä½¿ç”¨è¼¸å…¥è³‡æ–™ä¸­çš„è©å½™**ï¼(JSON æ˜¯äº‹å¯¦åŸºæº–)ã€‚
3.  **äººåé‡è¿° (é‡è¦)**ï¼šæ¯éš” 1-2 å€‹çŸ­å¥ï¼Œæˆ–è€…åœ¨æ”»é˜²è½‰æ›æ™‚ï¼Œ**å‹™å¿…å¸¶ä¸Šçƒå“¡åå­—**ã€‚
    * âŒ ä¸å¥½ï¼šæ®ºçƒï¼æŒ‘é«˜ï¼åˆæ®ºçƒï¼
    * âœ… å®Œç¾ï¼šSakuraæ®ºçƒï¼TanæŒ‘é«˜ï¼Miyauå†æ‰£æ®ºï¼
4.  **åš´æ ¼é™é•·**ï¼šè‹¥é™åˆ¶å¾ˆçŸ­ (å¦‚ < 6)ï¼Œçµ•ä¸èƒ½å¯«é•·å¥ï¼Œè«‹ç”¨å–®è© (å¦‚ï¼šå¾—åˆ†ï¼)ã€‚
5.  **é‡è¤‡å³ç¸½çµ**ï¼šå¦‚æœåŒ…å«é‡è¤‡å‹•ä½œ (å¦‚ï¼šæ®ºçƒ->æŒ‘çƒ->æ®ºçƒ)ï¼Œè«‹æ”¹ç”¨**ç¸½çµèªªæ˜** (å¦‚ï¼šã€Œé›™æ–¹æ¿€çƒˆæ”»é˜²ï¼ã€)ã€‚
6.  **ä¸é‡è¤‡**ï¼šä¸Šä¸‹æ™‚æ®µå…§å®¹è‹¥ç›¸ä¼¼ï¼Œè«‹æ›å€‹èªªæ³•æˆ–åŠ èªæ°£è©ã€‚
7.  **å®Œæ•´æ€§**ï¼šå¥å­å¿…é ˆæ˜¯å®Œæ•´çš„ã€Œçƒå“¡+å‹•ä½œã€çµæ§‹ï¼Œä¸è¦ç•™ä¸‹åªæœ‰åå­—çš„æ–·å¥ã€‚
    * âŒ éŒ¯èª¤ï¼šæ«»æœ¬å†æ®ºï¼é™³åº·
    * âœ… æ­£ç¢ºï¼šæ«»æœ¬å†æ®ºï¼é™³åº·æ“‹ç¶²ï¼
8.  **è¦–è¦ºåŠ åˆ† (Visuals)**ï¼šè«‹è§€å¯Ÿå½±ç‰‡ç´°ç¯€ï¼ŒåŠ å…¥**å½¢å®¹è©**æˆ–**æƒ…ç·’**ï¼Œä½†ä¸è¦æ”¹è®Šå‹•ä½œæœ¬è³ªã€‚
    * âŒ å¹³æ·¡ï¼šTanæ®ºçƒã€‚
    * âœ… ç”Ÿå‹•ï¼šTan**èºèµ·é‡æ‰£**ï¼ (è§€å¯Ÿåˆ°è·³å¾ˆé«˜)
    * âœ… ç”Ÿå‹•ï¼šMiyau**æ¥µé™**æ•‘çƒï¼ (è§€å¯Ÿåˆ°å‹•ä½œå¾ˆå‹‰å¼·)

ğŸ“Œ **è¼¸å…¥è³‡æ–™ç¯„ä¾‹ï¼š**
* ID: 0 | é™åˆ¶: 20 | å…§å®¹: æ®ºçƒ -> æŒ‘çƒ -> æ®ºçƒ -> æ“‹ç¶²
* ID: 1 | é™åˆ¶: 4 | å…§å®¹: æ®ºçƒ (å¾—åˆ†)

ğŸ“Œ **è¼¸å‡ºæ ¼å¼ (JSON é™£åˆ—)ï¼š**
æ³¨æ„ï¼šåªéœ€è¦å›å‚³ ID å’Œ Textã€‚
[
  {"id": 0, "text": "Sakuramotoé€£çºŒçŒ›æ”»ï¼ŒTané ‘å¼·æ“‹ä¸‹ï¼"},
  {"id": 1, "text": "æ®ºçƒå¾—åˆ†ï¼"}
]

ğŸ“Š **å¾…è™•ç†åˆ—è¡¨ (è«‹ä¾æ­¤ç‚ºæº–)ï¼š**
{{ event_data }}

è«‹è¼¸å‡º JSONï¼š
"""

prompt_builder = PromptBuilder(template=narrative_template, required_variables=["event_data"])

add_video_s2 = AddVideo2Prompt()
gemini_s2 = GeminiGenerator(project_id="ai-anchor-462506", location="us-central1", model="gemini-2.5-flash")

pipeline_s2 = Pipeline()
pipeline_s2.add_component(instance=prompt_builder, name="prompt_builder")
pipeline_s2.add_component(instance=add_video_s2, name="add_video")
pipeline_s2.add_component(instance=gemini_s2, name="llm")
pipeline_s2.connect("prompt_builder.prompt", "add_video.prompt")
pipeline_s2.connect("add_video.prompt", "llm.prompt")

# ========== 5. æ ¸å¿ƒåŠŸèƒ½ï¼šè™•ç†å–®ä¸€å½±ç‰‡ ==========
def process_single_video_stage2(video_path, event_json_path, output_folder):
    """
    è™•ç†å–®ä¸€å½±ç‰‡ï¼šè®€å– JSON -> èšåˆ -> ç”Ÿæˆæ•˜äº‹
    å›å‚³ï¼šç”Ÿæˆçš„ JSON è·¯å¾‘ (å¤±æ•—å›å‚³ None)
    """
    os.makedirs(output_folder, exist_ok=True)
    base_name = os.path.splitext(os.path.basename(video_path))[0]
    
    try:
        with VideoFileClip(video_path) as clip: total_duration = clip.duration
    except: total_duration = 30.0 

    try:
        with open(event_json_path, 'r', encoding='utf-8') as f: 
            data = json.load(f)
            nested_events = data.get("events", []) if isinstance(data, dict) else data
            video_uri = data.get("segment_video_uri", "") if isinstance(data, dict) else ""
    except: return None

    if not nested_events: return None

    # --- A. æ•¸æ“šèšåˆé‚è¼¯ (çœç•¥é‡è¤‡ä»£ç¢¼ï¼Œè«‹ç›´æ¥è¤‡è£½ä¹‹å‰çš„èšåˆé‚è¼¯) ---
    # ... (é€™è£¡è«‹æ”¾å…¥ä¹‹å‰çš„ RALLY_TYPES, chunk_events, buffer_chunk ç­‰å®Œæ•´èšåˆé‚è¼¯) ...
    # ç‚ºç¯€çœç¯‡å¹…ï¼Œé€™è£¡å‡è¨­ chunk_events å·²ç¶“ç”Ÿæˆå¥½äº†
    
    # ********** ç‚ºäº†å®Œæ•´æ€§ï¼Œè«‹å°‡ä¸Šä¸€ç‰ˆå®Œæ•´çš„èšåˆä»£ç¢¼è²¼åœ¨é€™è£¡ **********
    # (åŒ…å« INTRO, è¿´åœˆè™•ç†åŸå§‹å€å¡Š, OUTRO)
    RALLY_TYPES = ["Exchange", "Smash", "Defend"]
    chunk_events = [] 
    global_id_counter = 0
    
    # 1. INTRO
    first_chunk_start = parse_time_str(nested_events[0].get("start_time", "0:00.0"))
    intro_limit = int(first_chunk_start * SYLLABLES_PER_SEC)
    if intro_limit > MAX_INTRO_OUTRO_SYLLABLES: intro_limit = MAX_INTRO_OUTRO_SYLLABLES
    if intro_limit >= 8:
            chunk_events.append({
            "global_id": "INTRO",
            "start_sec": 0.0,
            "end_sec": first_chunk_start,
            "limit": intro_limit,
            "info": "é–‹å ´ç©ºç™½"
        })
    last_event_end = 0.0
    
    # 2. èšåˆè¿´åœˆ
    buffer_chunk = None
    for chunk in nested_events:
        chunk_start = parse_time_str(chunk.get("start_time", "0:00.0"))
        chunk_end = parse_time_str(chunk.get("end_time", "0:00.0"))
        inner_list = chunk.get("events", [])
        if not inner_list: continue
        actions_str = " -> ".join([f"{ev.get('player')}{ev.get('action')}" for ev in inner_list])
        is_pure_rally = all(ev.get('category') in RALLY_TYPES for ev in inner_list) and \
                        not any(ev.get('category') == 'Score' for ev in inner_list)
        current_chunk = {"start": chunk_start, "end": chunk_end, "info": actions_str, "is_rally": is_pure_rally}

        if buffer_chunk:
            potential_dur = current_chunk["end"] - buffer_chunk["start"]
            is_mergeable = (buffer_chunk["is_rally"] and current_chunk["is_rally"] and potential_dur <= MAX_RALLY_DURATION)
            if is_mergeable:
                buffer_chunk["end"] = current_chunk["end"]
                buffer_chunk["info"] += f" -> {current_chunk['info']}"
            else:
                dur = buffer_chunk["end"] - buffer_chunk["start"]
                limit = int(dur * SYLLABLES_PER_SEC)
                if limit > 3:
                    chunk_events.append({"global_id": global_id_counter, "start_sec": buffer_chunk["start"], "end_sec": buffer_chunk["end"], "limit": limit, "info": buffer_chunk["info"]})
                    global_id_counter += 1
                buffer_chunk = current_chunk
        else:
            buffer_chunk = current_chunk
        last_event_end = max(last_event_end, chunk_end)

    if buffer_chunk:
        dur = buffer_chunk["end"] - buffer_chunk["start"]
        limit = int(dur * SYLLABLES_PER_SEC)
        if limit > 3:
            chunk_events.append({"global_id": global_id_counter, "start_sec": buffer_chunk["start"], "end_sec": buffer_chunk["end"], "limit": limit, "info": buffer_chunk["info"]})
            global_id_counter += 1

    # 3. OUTRO
    outro_dur = total_duration - last_event_end
    outro_limit = int(outro_dur * SYLLABLES_PER_SEC)
    if outro_limit > MAX_INTRO_OUTRO_SYLLABLES: outro_limit = MAX_INTRO_OUTRO_SYLLABLES
    if outro_limit >= 8:
        chunk_events.append({"global_id": "OUTRO", "start_sec": last_event_end, "end_sec": total_duration, "limit": outro_limit, "info": "çµå°¾ç©ºç™½"})

    # --- B. å‘¼å« LLM ---
    llm_input_data = []
    for e in chunk_events:
        llm_input_data.append({"id": e["global_id"], "constraint": f"é™ {e['limit']} éŸ³ç¯€", "content": e["info"]})
    
    try:
        res = pipeline_s2.run({
            "add_video": {"uri": video_uri},
            "prompt_builder": {"event_data": json.dumps(llm_input_data, ensure_ascii=False, indent=2)}
        })
        reply = res["llm"]["replies"][0].strip()
        if reply.startswith("```"): reply = reply.split("\n", 1)[1].rsplit("\n", 1)[0]
        generated_list = json.loads(reply)
        generated_map = {str(item["id"]): item["text"] for item in generated_list}
    except Exception as e:
        print(f"âŒ [Stage 2 éŒ¯èª¤] {e}")
        return None

    # --- C. è¼¸å‡ºçµæœ ---
    commentary = []
    for chunk in chunk_events:
        gid = str(chunk["global_id"])
        text_content = generated_map.get(gid)
        if not text_content: continue 

        duration = chunk["end_sec"] - chunk["start_sec"]
        
        # å¯¬å®¹æˆªæ–·
        validation_duration = duration
        if gid in ["INTRO", "OUTRO"]: validation_duration = min(duration, 5.0)
        
        estimated_dur = estimate_speech_time(text_content)
        if estimated_dur > (validation_duration * 1.2):
            ratio = (validation_duration * 1.2) / estimated_dur
            safe_length = int(len(text_content) * ratio)
            text_content = text_content[:safe_length].rstrip("ï¼Œ,")

        emotion = "æ¿€å‹•" if "æ®ºçƒ" in chunk["info"] or "å¾—åˆ†" in chunk["info"] else "å¹³ç©©"

        # å»é‡
        if commentary and len(text_content) >= 2 and len(commentary[-1]["text"]) >= 2:
            check_len = min(5, len(text_content), len(commentary[-1]["text"]))
            if text_content[:check_len] == commentary[-1]["text"][:check_len]:
                commentary[-1]["end_time"] = seconds_to_timecode(chunk["end_sec"])
                prev_start = parse_time_str(commentary[-1]["start_time"])
                new_dur = chunk["end_sec"] - prev_start
                commentary[-1]["time_range"] = format_duration(new_dur)
                continue

        commentary.append({
            "start_time": seconds_to_timecode(chunk["start_sec"]),
            "end_time": seconds_to_timecode(chunk["end_sec"]),
            "time_range": format_duration(duration),
            "emotion": emotion,
            "text": text_content
        })

    output_filename = f"{base_name}.json"
    output_path = os.path.join(output_folder, output_filename)
    if commentary:
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump({"segment": os.path.basename(video_path), "commentary": commentary}, f, ensure_ascii=False, indent=2)
        return output_path
    else:
        return None

# ========== 6. ç¨ç«‹é‹è¡Œæ¨¡å¼ ==========
if __name__ == "__main__":
    video_folder = "D:/Vs.code/AI_Anchor/backend/video_splitter/badminton_segments"
    event_json_folder = "D:/Vs.code/AI_Anchor/backend/gemini/event_analysis_output"
    output_folder = "D:/Vs.code/AI_Anchor/backend/gemini/final_narratives"
    
    print(f"\nğŸš€ [ç¨ç«‹æ¨¡å¼] Stage 2 æ‰¹æ¬¡å•Ÿå‹•...")
    if os.path.exists(event_json_folder):
        files = sorted([f for f in os.listdir(event_json_folder) if f.endswith("_event.json")])
        for f in tqdm(files, desc="Processing"):
            base = f.replace("_event.json", "")
            vid_path = os.path.join(video_folder, f"{base}.mp4")
            json_path = os.path.join(event_json_folder, f)
            if os.path.exists(vid_path):
                res = process_single_video_stage2(vid_path, json_path, output_folder)
                if res: print(f"  -> Saved: {os.path.basename(res)}")
    else:
        print("âŒ æ‰¾ä¸åˆ° JSON è³‡æ–™å¤¾")