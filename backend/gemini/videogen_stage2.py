import os
import json
import re
from datetime import timedelta
from moviepy.editor import VideoFileClip
from vertexai.generative_models import Part
from haystack_integrations.components.generators.google_vertex import VertexAIGeminiGenerator
from haystack import component, Pipeline
from haystack.components.builders import PromptBuilder
from tqdm import tqdm

# ========== 1. è¨­å®šèˆ‡æ†‘è­‰ ==========
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
cred_path = os.path.join(PROJECT_ROOT, "credentials", "ai-anchor-462506-7887b7105f6a.json")
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = cred_path

# ========== 2. é—œéµåƒæ•¸ ==========
SYLLABLES_PER_SEC = 4.5      
MIN_EVENT_DURATION = 1.0      
MAX_RALLY_DURATION = 4.5
MIN_GAP_DURATION = 3.0        
MAX_INTRO_OUTRO_SYLLABLES = 30 
MERGE_THRESHOLD = 1.2 # [æ–°å¢] å¼·åˆ¶åˆä½µé–¾å€¼ï¼šè‹¥ç‰‡æ®µçŸ­æ–¼ 1.2 ç§’ï¼Œå¼·åˆ¶åˆä½µåˆ°ä¸‹ä¸€æ®µ

# å…¨åŸŸæ­·å²ç´€éŒ„
NARRATIVE_HISTORY = [] 
HISTORY_WINDOW_SIZE = 3 

# ========== 3. å·¥å…·å‡½æ•¸ ==========
def seconds_to_timecode(seconds):
    m, s = divmod(seconds, 60)
    h, m = divmod(m, 60)
    return f"{int(h)}:{int(m):02d}:{s:04.1f}"

def format_duration(seconds):
    m = int(seconds // 60)
    s = seconds % 60
    return f"{m}:{s:04.1f}"

def parse_time_str(t_str):
    try:
        if not t_str: return 0.0
        parts = t_str.strip().split(':')
        sec = 0.0
        if len(parts) == 3: sec += float(parts[-3]) * 3600
        if len(parts) >= 2: sec += float(parts[-2]) * 60
        sec += float(parts[-1])
        return sec
    except: return 0.0

def estimate_speech_time(text):
    if not text: return 0.0
    chinese_chars = re.findall(r'[\u4e00-\u9fff]', text)
    text_no_zh = re.sub(r'[\u4e00-\u9fff]', ' ', text)
    text_clean_en = re.sub(r'[^\w\s]', '', text_no_zh)
    english_words = text_clean_en.split()
    count_punc = len(re.findall(r'[ï¼Œã€‚ï¼,.]', text))
    total_units = (len(chinese_chars) * 1.0) + (len(english_words) * 1.3) + (count_punc * 0.4)
    return total_units / SYLLABLES_PER_SEC

# ========== 4. Pipeline åˆå§‹åŒ– ==========
@component
class AddVideo2Prompt:
    @component.output_types(prompt=list)
    def run(self, uri: str, prompt: str):
        return {"prompt": [Part.from_uri(uri, mime_type="video/mp4"), prompt]}

@component
class GeminiGenerator:
    def __init__(self, project_id, location, model):
        self.project_id, self.location, self.model = project_id, location, model
    @component.output_types(replies=list)
    def run(self, prompt: list):
        generator = VertexAIGeminiGenerator(project_id=self.project_id, location=self.location, model=self.model)
        return {"replies": generator.run(prompt)["replies"]}

# ========== 5. Prompt æ¨¡æ¿ ==========
narrative_template = """ 
1. è§’è‰²è¨­å®š (Role)
ä½ æ˜¯ä¸€ä½**è³‡æ·±ã€ç†±è¡€ä¸”å…·å‚™æˆ°è¡“æ´å¯ŸåŠ›**çš„é ‚ç´šè³½äº‹ä¸»æ’­ã€‚
ä½ çš„ç›®æ¨™æ˜¯é€éè²éŸ³å°‡è§€çœ¾å¸¶å…¥è³½å ´ã€‚ä½ çš„è§£èªªé¢¨æ ¼ï¼š
- **æ‹’çµ•å¹³é‹ªç›´æ•˜**ï¼šä¸è¦ç•¶ã€Œå ±å¹•å“¡ã€ï¼Œè¦ç•¶ã€Œèªªæ›¸äººã€ã€‚
- **å¼·èª¿å› æœé—œä¿‚**ï¼šè§£é‡‹å‹•ä½œèƒŒå¾Œçš„æ„åœ–èˆ‡çµæœï¼ˆä¾‹å¦‚ï¼šä¸åªæ˜¯èªªã€Œä»–æ®ºçƒã€ï¼Œè¦èªªã€Œé€™è¨˜æ®ºçƒç ´å£äº†å°æ‰‹é‡å¿ƒã€ï¼‰ã€‚
- **å£èªåŒ– (TTS Friendly)**ï¼šä½¿ç”¨é©åˆæœ—è®€çš„çŸ­å¥ï¼Œé¿å…ç”Ÿç¡¬çš„æ›¸é¢ç”¨èªã€‚
- **æ³¨æ„ç´°ç¯€**ï¼šè«‹å–„ç”¨detailä¾†è±å¯Œæ–‡æœ¬è§£èªªã€‚

2. ä¸Šä¸‹æ–‡è³‡è¨Š (Context)
- **æ­·å²æˆ°æ³ (Flow)**ï¼š
{{ prev_context }}
*(è«‹ç¹¼æ‰¿ä¸Šè¿°çš„èªæ°£èˆ‡æƒ…ç·’ï¼Œç¢ºä¿è§£èªªæµæš¢ä¸æ–·å±¤)*

- **è¼¸å…¥ä¾†æº**ï¼šçµåˆ **JSON äº‹ä»¶éˆ** èˆ‡ **è¦–è¦ºç•«é¢** é€²è¡Œè§£èªªã€‚

3. ä»»å‹™åŸ·è¡Œ (Tasks)
ä½ çš„å·¥ä½œæ˜¯è¦å°‡ä¸€ç³»åˆ—çš„äº‹ä»¶è½‰åŒ–ç‚ºç”Ÿå‹•çš„è§£èªªæ–‡æœ¬ï¼š

- **ç‰¹æ®Šä»»å‹™æŒ‡å¼• (Special Tasks)**ï¼š
    - **[Intro]**: å½±ç‰‡å‰›é–‹å§‹ã€‚è«‹ç°¡å–®é–‹å ´ï¼Œä»‹ç´¹é¸æ‰‹æˆ–ç•¶å‰æ¯”åˆ†å±€å‹¢ã€‚
    - **[Gap]**: æ¯”è³½é–“éš™ã€‚è«‹æè¿°çƒå“¡çš„å¿ƒç†ç‹€æ…‹ã€æ“¦æ±—ã€æ›çƒã€èª¿æ•´å‘¼å¸ã€‚
    - **[Outro]**: å½±ç‰‡çµæŸã€‚è«‹å¿«é€Ÿç¸½çµå‰›å‰›é€™çƒçš„çµæœã€å¾—åˆ†è€…ã€‚
    - **[Replay]**: ç²¾å½©å›æ”¾/æ…¢å‹•ä½œã€‚è«‹**æ·±å…¥åˆ†æ**å‰›æ‰å‹•ä½œçš„æŠ€è¡“ç´°ç¯€ï¼ˆå¦‚ï¼šæ‰‹è…•è®ŠåŒ–ã€å‡å‹•ä½œã€è…³æ­¥ç§»å‹•ï¼‰ï¼Œèªæ°£å°ˆæ¥­ä¸”å¸¶æœ‰è®šå˜†ã€‚

4. åš´æ ¼ç¦ä»¤ (Strict Prohibitions)
â›”ï¸ **é•è¦å°‡å°è‡´ç³»çµ±éŒ¯èª¤ï¼š**
- **ğŸˆ² ç¦æ­¢æµæ°´å¸³**ï¼šçµ•å°ä¸è¦ä½¿ç”¨ã€Œç„¶å¾Œ...æ¥è‘—...ã€é€™ç¨®é€£æ¥è©ã€‚è«‹ç”¨**å› æœé—œä¿‚**ä¸²è¯ï¼ˆã€Œé€¼å¾—å°æ‰‹...ã€ã€ã€Œå°è‡´...ã€ï¼‰ã€‚
- **ğŸˆ² ç¦æ­¢é–“éš™å¹»è¦º**ï¼šåœ¨ `[Gap]` çµ•å°ä¸èƒ½æè¿°æ–°çš„æ“Šçƒå‹•ä½œï¼ˆæ®ºçƒ/ç™¼çƒï¼‰ã€‚åªèƒ½è¬›è©•è«–ã€‚
- **ğŸˆ² ç¦æ­¢æœªåœå…ˆçŸ¥**ï¼šè‹¥ `[Score]` æœªå‡ºç¾ï¼Œä¸å¯æå‰å®£å‘Šå¾—åˆ†ã€‚
- **ğŸˆ² åš´æ ¼å­—æ•¸æ§åˆ¶**ï¼š`constraint` æ˜¯ç‰©ç†é™åˆ¶ã€‚**å¯§å¯è©±å°‘ç²¾ç°¡ï¼Œçµ•ä¸è¶…æ™‚çˆ†éŸ³ã€‚**

5. è¼¸å‡ºæ ¼å¼
è¼¸å‡ºç´” JSON é™£åˆ—ï¼ŒåŒ…å« `id` å’Œ `text` å…©å€‹æ¬„ä½ã€‚

6. ç¯„ä¾‹ (Example)
**è¼¸å…¥:**
[
    {"id": 0, "constraint": "é™ 14 éŸ³ç¯€", "content": "[Serve] æˆ´è³‡ç© - ç™¼çƒ (éé«˜) -> [Offense] é™³é›¨è² - æ’²çƒ (ä¸‹å£“)"},
    {"id": 1, "constraint": "é™ 8 éŸ³ç¯€", "content": "[Score] ç„¡ - ç•Œå…§å¾—åˆ†"},
    {"id": 2, "constraint": "é™ 12 éŸ³ç¯€", "content": "[Gap] å°æ‰‹æ‡Šæƒ±"}
]
**è¼¸å‡º:**
[
    {"id": 0, "text": "å°æˆ´é€™çƒç™¼é«˜äº†ï¼é™³é›¨è²æ²’æ”¾éæ©Ÿæœƒç›´æ¥ä¸‹å£“ï¼"},
    {"id": 1, "text": "è½åœ°å¾—åˆ†ï¼é€™çƒæŠ“å¾—å¤ªæº–äº†ï¼"},
    {"id": 2, "text": "å°æˆ´è‡‰ä¸Šéœ²å‡ºäº†æ‡Šæƒ±çš„è¡¨æƒ…ã€‚"}
]

ğŸ“Š **å¾…è™•ç†æ•¸æ“šï¼š**
{{ event_data }}

è«‹è¼¸å‡º JSONï¼š
"""

prompt_builder = PromptBuilder(template=narrative_template, required_variables=["event_data","prev_context"])

add_video_s2 = AddVideo2Prompt()
gemini_s2 = GeminiGenerator(project_id="ai-anchor-462506", location="us-central1", model="gemini-2.5-flash")

pipeline_s2 = Pipeline()
pipeline_s2.add_component(instance=prompt_builder, name="prompt_builder")
pipeline_s2.add_component(instance=add_video_s2, name="add_video")
pipeline_s2.add_component(instance=gemini_s2, name="llm")
pipeline_s2.connect("prompt_builder.prompt", "add_video.prompt")
pipeline_s2.connect("add_video.prompt", "llm.prompt")

# ========== 6. è¼”åŠ©å‡½å¼ (å«æœ€çµ‚é˜²ç·š) ==========
def _flush_chunk(results_list, chunk_data, global_counter_ref):
    dur = chunk_data["end"] - chunk_data["start"]
    limit = int(dur * SYLLABLES_PER_SEC)
    should_keep = False
    
    # åˆ¤æ–·é¡å‹
    is_gap = "é–“éš™" in chunk_data.get("info", "") or "Gap" in chunk_data.get("info", "")
    is_crucial = chunk_data.get("is_crucial", False)

    # ğŸ”¥ æœ€çµ‚é˜²ç·šï¼šè‹¥é€šéäº†è¿´åœˆçš„ç¯©é¸ï¼Œé€™è£¡åšæœ€å¾Œçš„æ ¼å¼ä¿éšœ
    if is_crucial or is_gap:
        # é—œéµæ™‚åˆ»/é–“éš™ï¼šå¼·åˆ¶ä¿ç•™ä¸¦çµ¦äºˆæœ€å°å­—æ•¸ç©ºé–“
        limit = max(limit, 6) 
        should_keep = True
    else:
        # æ™®é€š Rallyï¼šè‹¥é‚„æ˜¯å¤ªçŸ­ä¸”æ²’è¢«åˆä½µï¼Œä¸Ÿæ£„ (é€™æ˜¯æœ€å¾Œä¸€é“æ¿¾ç¶²)
        if limit >= 4:
            should_keep = True

    if should_keep:
        results_list.append({
            "global_id": global_counter_ref[0], 
            "start_sec": chunk_data["start"], 
            "end_sec": chunk_data["end"], 
            "limit": limit, 
            "info": chunk_data["info"]
        })
        global_counter_ref[0] += 1


# ========== 7. æ ¸å¿ƒåŠŸèƒ½ï¼šè™•ç†å–®ä¸€å½±ç‰‡ (å·²ä¿®æ­£æ™‚é–“è»¸æ’è»¸é‚è¼¯) ==========
def process_single_video_stage2(video_path, event_json_path, output_folder):
    global NARRATIVE_HISTORY

    os.makedirs(output_folder, exist_ok=True)
    base_name = os.path.splitext(os.path.basename(video_path))[0]
    
    # 0. åŸºç¤è³‡è¨Šè®€å–
    try:
        with VideoFileClip(video_path) as clip: total_duration = clip.duration
    except: total_duration = 30.0 

    try:
        with open(event_json_path, 'r', encoding='utf-8') as f: 
            data = json.load(f)
            events = data.get("events", [])
            video_uri = data.get("video_uri", "") or data.get("segment_video_uri", "")
    except Exception as e:
        print(f"âŒ è®€å– JSON å¤±æ•—: {e}")
        return None

    if not events: return None

    # ==========================================
    # Phase 1: äº‹ä»¶èšåˆ (Aggregation) - å¼·åˆ¶åˆ‡ç‰‡ç‰ˆ
    # ==========================================
    narrative_blocks = []
    current_block_events = []
    block_start_raw = 0.0
    
    events.sort(key=lambda x: parse_time_str(x.get("start_time", "0:00")))
    last_event_end = 0.0
    
    for i, event in enumerate(events):
        start = parse_time_str(event.get("start_time"))
        if start > total_duration - 0.5: continue

        end = parse_time_str(event.get("end_time"))
        if end == 0.0: end = start + 1.0
        
        cat = event.get("category", "General")
        sub = event.get("subject") or event.get("player", "çƒå“¡")
        act = event.get("action", "")
        det = event.get("detail", "")
        event_str = f"[{cat}] {sub} - {act} ({det})"

        # --- ğŸ”¥ ä¿®æ”¹é»ï¼šå¼·åˆ¶åˆ‡ç‰‡é‚è¼¯ ---
        current_block_duration = end - block_start_raw
        gap_from_last = start - last_event_end
        
        is_new_block = False
        if not current_block_events:
            is_new_block = True
        elif gap_from_last > 1.2:  # é–“éš” > 1.2s æ–·å¥
            is_new_block = True
        elif len(current_block_events) >= 3: # ğŸ”¥ å‹•ä½œæ•¸é‡ >= 3 å¼·åˆ¶æ›å¥
            is_new_block = True
        elif current_block_duration > 3.5:   # ğŸ”¥ æ™‚é–“é•·åº¦ > 3.5s å¼·åˆ¶æ›å¥
            is_new_block = True
            
        if is_new_block:
            if current_block_events:
                narrative_blocks.append({
                    "type": "RALLY",
                    "raw_start": block_start_raw,
                    "raw_end": last_event_end,
                    "content": " -> ".join(current_block_events)
                })
            current_block_events = [event_str]
            block_start_raw = start
        else:
            current_block_events.append(event_str)
        
        last_event_end = end

    if current_block_events:
        narrative_blocks.append({
            "type": "RALLY",
            "raw_start": block_start_raw,
            "raw_end": last_event_end,
            "content": " -> ".join(current_block_events)
        })

    # ==========================================
    # Phase 2: é å…ˆæ’ç¨‹ (Pre-Scheduling) - è†¨è„¹èˆ‡å¡«ç©º
    # ==========================================
    scheduled_tasks = [] 
    audio_cursor = 0.0 
    
    DELAY_MAP = {
        "setup": 2.0, "serve": 2.0, "offense": 0.6, "smash": 0.5,    
        "defense": 0.7, "score": 0.1, "gap": 0.0, "intro": 0.0, "outro": 0.0, "default": 0.8   
    }

    # --- ğŸ”¥ ä¿®æ”¹é» 1: Intro å¡«ç©º ---
    first_block_start = narrative_blocks[0]["raw_start"] if narrative_blocks else total_duration
    if first_block_start > 3.0:
        intro_dur = min(first_block_start - 0.5, 6.0)
        scheduled_tasks.append({
            "id": "intro",
            "final_start": 0.0,
            "final_end": intro_dur,
            "duration": intro_dur,
            "type": "INTRO",
            "raw_content": "æ¯”è³½é–‹å§‹",
            "prompt_constraint": f"é™ {int(intro_dur * SYLLABLES_PER_SEC)} éŸ³ç¯€",
            "prompt_content": "[Intro] é€™æ˜¯æ¯”è³½é–‹å§‹ï¼Œè«‹åšç°¡å–®é–‹å ´ä»‹ç´¹ã€‚"
        })
        audio_cursor = intro_dur

    # --- è¿´åœˆæ’ç¨‹ ---
    for idx, block in enumerate(narrative_blocks):
        # A. ç†æƒ³æ™‚é–“
        delay = 0.8
        content_lower = block["content"].lower()
        for k, v in DELAY_MAP.items():
            if k in content_lower: delay = v; break
        ideal_start = block["raw_start"] + delay
        
        # --- ğŸ”¥ ä¿®æ”¹é» 2: Gap å¡«ç©º ---
        gap_duration = ideal_start - audio_cursor
        if gap_duration > 4.0:
            fill_dur = min(gap_duration - 0.5, 5.0)
            gap_start = audio_cursor + 0.2
            scheduled_tasks.append({
                "id": f"gap_{idx}",
                "final_start": gap_start,
                "final_end": gap_start + fill_dur,
                "duration": fill_dur,
                "type": "GAP",
                "raw_content": "é–“éš™",
                "prompt_constraint": f"é™ {int(fill_dur * SYLLABLES_PER_SEC)} éŸ³ç¯€",
                "prompt_content": "[Gap] é›™æ–¹èª¿æ•´ç¯€å¥/çƒå“¡å¿ƒç†/æº–å‚™ä¸‹ä¸€çƒ"
            })
            audio_cursor = gap_start + fill_dur

        # C. æ’ç¨‹ç•¶å‰ Block
        start_time = max(ideal_start, audio_cursor + 0.2)
        
        # --- ğŸ”¥ ä¿®æ”¹é» 3: æ™‚é–“è†¨è„¹è¨ˆç®— ---
        raw_span = block["raw_end"] - block["raw_start"]
        base_min_duration = 3.5 # ä¿åº• 3.5 ç§’
        target_dur = min(raw_span + 2.0, 6.0) # åŸå§‹+2ç§’ï¼Œä¸Šé™6ç§’
        target_dur = max(target_dur, base_min_duration) # æ‡‰ç”¨ä¿åº•

        # Lookahead: åªæœ‰é‡åˆ°é—œéµçƒæ‰ç¨å¾®è®“è·¯
        if idx < len(narrative_blocks) - 1:
            next_content = narrative_blocks[idx+1]["content"].lower()
            next_raw_start = narrative_blocks[idx+1]["raw_start"]
            if "score" in next_content or "smash" in next_content:
                next_ideal = next_raw_start + 0.5
                if next_ideal < start_time + target_dur:
                    compressed = next_ideal - start_time
                    target_dur = max(compressed, 2.5)

        end_time = start_time + target_dur
        if end_time > total_duration: end_time = total_duration
        
        final_duration = end_time - start_time
        if final_duration < 0.8: continue

        syllable_count = int(final_duration * SYLLABLES_PER_SEC)
        syllable_count = max(syllable_count, 5)

        scheduled_tasks.append({
            "id": idx,
            "final_start": start_time,
            "final_end": end_time,
            "duration": final_duration,
            "type": block["type"],
            "raw_content": block["content"],
            "prompt_constraint": f"é™ {syllable_count} éŸ³ç¯€",
            "prompt_content": block["content"]
        })
        audio_cursor = end_time

    # ç›®çš„ï¼šé¿å…æœ€å¾Œå‰©é¤˜æ™‚é–“å¤ªé•·(å¦‚17ç§’)å°è‡´AIå¯«ä½œæ–‡ã€‚å°‡å…¶æ‹†è§£ç‚ºã€Œç¸½çµã€+ã€Œå›æ”¾åˆ†æã€ã€‚
    
    remaining_time = total_duration - audio_cursor
    
    if remaining_time > 12.0:
        # æƒ…æ³ A: å‰©é¤˜æ™‚é–“å……è£• -> æ‹†åˆ†ç‚º [Outro] + [Replay]
        
        # 1. å¿«é€Ÿç¸½çµ (Outro) - å›ºå®šçµ¦ 5 ç§’
        outro_dur = 5.0
        scheduled_tasks.append({
            "id": "outro_summary",
            "final_start": audio_cursor + 0.2,
            "final_end": audio_cursor + 0.2 + outro_dur,
            "duration": outro_dur,
            "type": "OUTRO",
            "raw_content": "çµå°¾ç¸½çµ",
            "prompt_constraint": f"é™ {int(outro_dur * SYLLABLES_PER_SEC)} éŸ³ç¯€",
            "prompt_content": "[Outro] æœ¬å›åˆçµæŸï¼Œå¿«é€Ÿç¸½çµå¾—åˆ†é—œéµã€‚"
        })
        # æ›´æ–°æŒ‡é‡ï¼Œç‚ºä¸‹ä¸€æ®µåšæº–å‚™
        audio_cursor += (0.2 + outro_dur)

        # 2. å›æ”¾åˆ†æ (Replay) - å¡«è£œå‰©é¤˜æ™‚é–“
        # è¨ˆç®—å¯ç”¨æ™‚é–“ï¼šå‰©é¤˜æ™‚é–“ - ç·©è¡ 1.0ç§’
        # è¨­å®šä¸Šé™ 8.0 ç§’ (é¿å…è¬›å¤ªä¹…)
        replay_dur = min(remaining_time - outro_dur - 1.0, 8.0) 
        
        if replay_dur > 3.0:
            scheduled_tasks.append({
                "id": "outro_replay",
                "final_start": audio_cursor + 0.5,
                "final_end": audio_cursor + 0.5 + replay_dur,
                "duration": replay_dur,
                "type": "REPLAY",
                "raw_content": "æ…¢å‹•ä½œåˆ†æ",
                "prompt_constraint": f"é™ {int(replay_dur * SYLLABLES_PER_SEC)} éŸ³ç¯€",
                "prompt_content": "[Replay] é€™æ˜¯ç²¾å½©é‡æ’­ç•«é¢ï¼Œè«‹æ·±å…¥åˆ†æå‰›æ‰å‹•ä½œçš„æŠ€è¡“ç´°ç¯€(å¦‚å‡å‹•ä½œæˆ–è½é»)ã€‚"
            })

    elif remaining_time > 3.0:
        # æƒ…æ³ B: å‰©é¤˜æ™‚é–“æ­£å¸¸ -> åªæœ‰ [Outro]
        # è¨­å®šä¸Šé™ 6.0 ç§’
        outro_dur = min(remaining_time - 0.5, 6.0)
        scheduled_tasks.append({
            "id": "outro",
            "final_start": audio_cursor + 0.2,
            "final_end": audio_cursor + 0.2 + outro_dur,
            "duration": outro_dur,
            "type": "OUTRO",
            "raw_content": "çµå°¾",
            "prompt_constraint": f"é™ {int(outro_dur * SYLLABLES_PER_SEC)} éŸ³ç¯€",
            "prompt_content": "[Outro] æœ¬å›åˆçµæŸï¼Œç¸½çµå‰›æ‰çš„ç²¾å½©è¡¨ç¾ã€‚"
        })

    if not scheduled_tasks:
        print(f"âš ï¸ [Skip] {base_name}: ç„¡æœ‰æ•ˆä»»å‹™")
        return None

    # ==========================================
    # Phase 3: ç”Ÿæˆè§£èªª (Generation) - å¸¶ Context ç‰ˆ
    # ==========================================
    
    # 1. æº–å‚™ä»»å‹™æ•¸æ“š
    llm_input_data = []
    for task in scheduled_tasks:
        llm_input_data.append({
            "id": task["id"],
            "constraint": task["prompt_constraint"], 
            "content": task["prompt_content"]
        })
        
    # 2. æº–å‚™æ­·å²ç´€éŒ„ (Context)
    if NARRATIVE_HISTORY:
        recent_history = NARRATIVE_HISTORY[-HISTORY_WINDOW_SIZE:]
        history_str = "\n".join([f"- {h}" for h in recent_history])
    else:
        history_str = "é€™æ˜¯æ¯”è³½çš„ç¬¬ä¸€å€‹ç‰‡æ®µï¼Œè«‹ç›´æ¥é–‹å§‹è§£èªªã€‚"

    try:
        # 3. åŸ·è¡Œ Pipeline (ğŸ”¥ é—œéµï¼šå¿…é ˆå‚³å…¥ prev_context)
        res = pipeline_s2.run({
            "add_video": {"uri": video_uri},
            "prompt_builder": {
                "event_data": json.dumps(llm_input_data, ensure_ascii=False, indent=2),
                "prev_context": history_str  # <--- é€™è¡Œå°±æ˜¯è§£æ±º Missing input çš„é—œéµ
            }
        })

        reply = res["llm"]["replies"][0].strip()
        
        # æ¸…æ´— JSON
        if "```" in reply:
            match = re.search(r'\[.*\]', reply, re.DOTALL)
            if match: reply = match.group()
        
        generated_list = json.loads(reply)
        generated_map = {str(item["id"]): item["text"] for item in generated_list}
        
    except Exception as e:
        print(f"âŒ [Stage 2 LLM éŒ¯èª¤] {e}")
        return None

    # ==========================================
    # Phase 4: è¼¸å‡ºçµ„è£ (Assembly)
    # ==========================================
    
    commentary = []
    segment_texts = []
    
    for task in scheduled_tasks:
        tid = str(task["id"]) # è½‰å­—ä¸²
        text = generated_map.get(tid, "")
        if not text: continue
        
        # ğŸ”¥ ä¿®æ”¹ï¼šå¢å¼·ç‰ˆæƒ…ç·’åˆ¤æ–·
        emotion = "å¹³ç©©" 
        content_lower = task["raw_content"].lower()
        task_type = task["type"]
        
        if task_type == "INTRO":
            emotion = "èˆ’ç·©"
        elif task_type == "OUTRO":
            emotion = "æ¿€å‹•" 
        elif task_type == "REPLAY":  # ğŸ”¥ æ–°å¢é€™è¡Œ
            emotion = "å°ˆæ¥­"       # å›æ”¾åˆ†ææ™‚ä½¿ç”¨å°ˆæ¥­/åˆ†æèªæ°£
        elif task_type == "GAP":
            emotion = "èˆ’ç·©"
        elif any(k in content_lower for k in ["score", "smash", "kill", "won", "winner"]):
            emotion = "æ¿€å‹•"
        elif any(k in content_lower for k in ["defense", "save", "foul", "out", "mistake"]):
            emotion = "ç·Šå¼µ"
        elif any(k in content_lower for k in ["serve", "prepare"]):
            emotion = "èˆ’ç·©"
        elif any(k in content_lower for k in ["miss", "error", "fail"]):
            emotion = "éºæ†¾"

        commentary.append({
            "start_time": seconds_to_timecode(task["final_start"]),
            "end_time": seconds_to_timecode(task["final_end"]),
            "time_range": format_duration(task["duration"]),
            "emotion": emotion,
            "text": text
        })
        segment_texts.append(text)

    # (å¾ŒçºŒå­˜æª”éƒ¨åˆ†ä¿æŒä¸è®Š)
    if segment_texts:
        NARRATIVE_HISTORY.append(" ".join(segment_texts))
        if len(NARRATIVE_HISTORY) > 10: NARRATIVE_HISTORY.pop(0)

    output_path = os.path.join(output_folder, f"{base_name}.json")
    if commentary:
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump({"segment": base_name, "commentary": commentary}, f, ensure_ascii=False, indent=2)
        return output_path
    else:
        return None


# ========== 8. ç¨ç«‹é‹è¡Œæ¨¡å¼ ==========
if __name__ == "__main__":
    video_folder = "D:/Vs.code/AI_Anchor/backend/video_splitter/badminton_segments"
    event_json_folder = "D:/Vs.code/AI_Anchor/backend/gemini/event_analysis_output"
    output_folder = "D:/Vs.code/AI_Anchor/backend/gemini/final_narratives"
    
    NARRATIVE_HISTORY = [] 
    
    print(f"\nğŸš€ [ç¨ç«‹æ¨¡å¼] Stage 2 (å‘å¾Œåˆä½µå¢å¼·ç‰ˆ) æ‰¹æ¬¡å•Ÿå‹•...")
    if os.path.exists(event_json_folder):
        files = sorted([f for f in os.listdir(event_json_folder) if f.endswith("_event.json")])
        for f in tqdm(files, desc="Processing"):
            base = f.replace("_event.json", "")
            vid_path = os.path.join(video_folder, f"{base}.mp4")
            json_path = os.path.join(event_json_folder, f)
            if os.path.exists(vid_path):
                res = process_single_video_stage2(vid_path, json_path, output_folder)
                if res: print(f"  -> Saved: {os.path.basename(res)}")
    else:
        print("âŒ æ‰¾ä¸åˆ° JSON è³‡æ–™å¤¾")