import os
import json
import re
from datetime import timedelta
from moviepy.editor import VideoFileClip
from vertexai.generative_models import Part
from haystack_integrations.components.generators.google_vertex import VertexAIGeminiGenerator
from haystack import component, Pipeline
from haystack.components.builders import PromptBuilder
from tqdm import tqdm

# ========== 1. è¨­å®šèˆ‡æ†‘è­‰ ==========
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
cred_path = os.path.join(PROJECT_ROOT, "credentials", "ai-anchor-462506-7887b7105f6a.json")
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = cred_path

# ========== 2. é—œéµåƒæ•¸ ==========
SYLLABLES_PER_SEC = 4.0       # èªé€Ÿæ§åˆ¶ (éŸ³ç¯€/ç§’)
MIN_EVENT_DURATION = 1.0      # æœ€å°æ™‚é•· (å°æ–¼æ­¤ç§’æ•¸å¼·åˆ¶åˆä½µ)
MAX_RALLY_DURATION = 4.5      # æœ€å¤§åˆä½µæ™‚é•· (è¶…éæ­¤ç§’æ•¸å¼·åˆ¶åˆ‡æ–·ï¼Œé¿å…å†·å ´)

# ========== 3. å·¥å…·å‡½æ•¸ ==========
def seconds_to_timecode(seconds):
    m, s = divmod(seconds, 60)
    h, m = divmod(m, 60)
    return f"{int(h)}:{int(m):02d}:{s:04.1f}"

def format_duration(seconds):
    m = int(seconds // 60)
    s = seconds % 60
    return f"{m}:{s:04.1f}"

def parse_time_str(t_str):
    try:
        if not t_str: return 0.0
        parts = t_str.strip().split(':')
        sec = 0.0
        if len(parts) == 3: sec += float(parts[-3]) * 3600
        if len(parts) >= 2: sec += float(parts[-2]) * 60
        sec += float(parts[-1])
        return sec
    except: return 0.0

def estimate_speech_time(text):
    if not text: return 0.0
    chinese_chars = re.findall(r'[\u4e00-\u9fff]', text)
    text_no_zh = re.sub(r'[\u4e00-\u9fff]', ' ', text)
    text_clean_en = re.sub(r'[^\w\s]', '', text_no_zh)
    english_words = text_clean_en.split()
    count_punc = len(re.findall(r'[ï¼Œã€‚ï¼,.]', text))
    total_units = (len(chinese_chars) * 1.0) + (len(english_words) * 1.3) + (count_punc * 0.4)
    return total_units / SYLLABLES_PER_SEC

# ========== 4. Haystack çµ„ä»¶ ==========
@component
class AddVideo2Prompt:
    @component.output_types(prompt=list)
    def run(self, uri: str, prompt: str):
        return {"prompt": [Part.from_uri(uri, mime_type="video/mp4"), prompt]}

@component
class GeminiGenerator:
    def __init__(self, project_id, location, model):
        self.project_id, self.location, self.model = project_id, location, model
    @component.output_types(replies=list)
    def run(self, prompt: list):
        generator = VertexAIGeminiGenerator(project_id=self.project_id, location=self.location, model=self.model)
        return {"replies": generator.run(prompt)["replies"]}

# ========== 5. Prompt æ¨¡æ¿ (æ–°å¢äººåå¼·èª¿è¦å‰‡) ==========
# ========== 5. Prompt æ¨¡æ¿ (æ•¸æ“š + è¦–è¦ºé›™é‡é©…å‹•) ==========
narrative_template = """ 
ä½ æ˜¯ä¸€ä½**è³‡æ·±ã€ç¯€å¥æ˜å¿«**çš„ç¾½çƒè³½äº‹å³æ™‚ä¸»æ’­ã€‚
ç¾åœ¨ä½ æœ‰å…©å€‹è³‡è¨Šä¾†æºï¼š
1.  **æ¯”è³½å½±ç‰‡**ï¼šè«‹è§€å¯Ÿç•«é¢ä¸­çš„ç²¾å½©ç´°ç¯€ã€çƒå“¡æƒ…ç·’èˆ‡æ“ŠçƒåŠ›é“ã€‚
2.  **æ™‚é–“å€å¡Šåˆ—è¡¨ (JSON)**ï¼šé€™æ˜¯ç²¾æº–çš„å‹•ä½œç´€éŒ„èˆ‡éŸ³ç¯€é™åˆ¶ã€‚

ğŸ¯ **ä½ çš„ä»»å‹™ï¼šè¦–è¦ºèˆ‡æ•¸æ“šçš„å®Œç¾çµåˆ**
è«‹æ ¹æ“š JSON çš„æŒ‡å¼•é–å®šæ™‚é–“æ®µï¼Œä¸¦**è§€çœ‹å½±ç‰‡**ä¾†è±å¯Œä½ çš„è§£èªªã€‚

**å…«å¤§é»ƒé‡‘è¦å‰‡ (è«‹åš´æ ¼éµå®ˆ)ï¼š**
1.  **æ¥µç°¡é¢¨æ ¼**ï¼šä½¿ç”¨ã€Œçƒå“¡+å‹•ä½œã€çš„çŸ­èªæ¨¡å¼ (å¦‚ï¼šMiyauæŒ‘é«˜ã€Tanæ®ºçƒ)ã€‚
2.  **è³‡æ–™æ­£ç¢ºæ€§ (é‡è¦)**ï¼š**äººå**èˆ‡**å‹•ä½œé¡å‹**å¿…é ˆç›´æ¥ä½¿ç”¨è¼¸å…¥è³‡æ–™ä¸­çš„è©å½™ï¼(JSON æ˜¯äº‹å¯¦åŸºæº–)ã€‚
3.  **äººåé‡è¿° (é‡è¦)**ï¼šæ¯éš” 1-2 å€‹çŸ­å¥ï¼Œæˆ–è€…åœ¨æ”»é˜²è½‰æ›æ™‚ï¼Œ**å‹™å¿…å¸¶ä¸Šçƒå“¡åå­—**ã€‚
    * âŒ ä¸å¥½ï¼šæ®ºçƒï¼æŒ‘é«˜ï¼åˆæ®ºçƒï¼
    * âœ… å®Œç¾ï¼šSakuraæ®ºçƒï¼TanæŒ‘é«˜ï¼Miyauå†æ‰£æ®ºï¼
4.  **åš´æ ¼é™é•·**ï¼šè‹¥é™åˆ¶å¾ˆçŸ­ (å¦‚ < 6)ï¼Œçµ•ä¸èƒ½å¯«é•·å¥ï¼Œè«‹ç”¨å–®è© (å¦‚ï¼šå¾—åˆ†ï¼)ã€‚
5.  **é‡è¤‡å³ç¸½çµ**ï¼šå¦‚æœåŒ…å«é‡è¤‡å‹•ä½œ (å¦‚ï¼šæ®ºçƒ->æŒ‘çƒ->æ®ºçƒ)ï¼Œè«‹æ”¹ç”¨**ç¸½çµèªªæ˜** (å¦‚ï¼šã€Œé›™æ–¹æ¿€çƒˆæ”»é˜²ï¼ã€)ã€‚
6.  **ä¸é‡è¤‡**ï¼šä¸Šä¸‹æ™‚æ®µå…§å®¹è‹¥ç›¸ä¼¼ï¼Œè«‹æ›å€‹èªªæ³•æˆ–åŠ èªæ°£è©ã€‚
7.  **å®Œæ•´æ€§**ï¼šå¥å­å¿…é ˆæ˜¯å®Œæ•´çš„ã€Œçƒå“¡+å‹•ä½œã€çµæ§‹ï¼Œä¸è¦ç•™ä¸‹åªæœ‰åå­—çš„æ–·å¥ã€‚
    * âŒ éŒ¯èª¤ï¼šæ«»æœ¬å†æ®ºï¼é™³åº·
    * âœ… æ­£ç¢ºï¼šæ«»æœ¬å†æ®ºï¼é™³åº·æ“‹ç¶²ï¼
8.  **è¦–è¦ºåŠ åˆ† (Visuals)**ï¼šè«‹è§€å¯Ÿå½±ç‰‡ç´°ç¯€ï¼ŒåŠ å…¥**å½¢å®¹è©**æˆ–**æƒ…ç·’**ï¼Œä½†ä¸è¦æ”¹è®Šå‹•ä½œæœ¬è³ªã€‚
    * âŒ å¹³æ·¡ï¼šTanæ®ºçƒã€‚
    * âœ… ç”Ÿå‹•ï¼šTan**èºèµ·é‡æ‰£**ï¼ (è§€å¯Ÿåˆ°è·³å¾ˆé«˜)
    * âœ… ç”Ÿå‹•ï¼šMiyau**æ¥µé™**æ•‘çƒï¼ (è§€å¯Ÿåˆ°å‹•ä½œå¾ˆå‹‰å¼·)

ğŸ“Œ **è¼¸å…¥è³‡æ–™ç¯„ä¾‹ï¼š**
* ID: 0 | é™åˆ¶: 20 | å…§å®¹: æ®ºçƒ -> æŒ‘çƒ -> æ®ºçƒ -> æ“‹ç¶²
* ID: 1 | é™åˆ¶: 4 | å…§å®¹: æ®ºçƒ (å¾—åˆ†)

ğŸ“Œ **è¼¸å‡ºæ ¼å¼ (JSON é™£åˆ—)ï¼š**
æ³¨æ„ï¼šåªéœ€è¦å›å‚³ ID å’Œ Textã€‚
[
  {"id": 0, "text": "Sakuramotoé€£çºŒçŒ›æ”»ï¼ŒTané ‘å¼·æ“‹ä¸‹ï¼"},
  {"id": 1, "text": "æ®ºçƒå¾—åˆ†ï¼"}
]

ğŸ“Š **å¾…è™•ç†åˆ—è¡¨ (è«‹ä¾æ­¤ç‚ºæº–)ï¼š**
{{ event_data }}

è«‹è¼¸å‡º JSONï¼š
"""

prompt_builder = PromptBuilder(template=narrative_template, required_variables=["event_data"])

# ========== 6. Pipeline ==========
pipeline = Pipeline()
pipeline.add_component(instance=prompt_builder, name="prompt_builder")
pipeline.add_component(instance=AddVideo2Prompt(), name="add_video")
pipeline.add_component(instance=GeminiGenerator(project_id="ai-anchor-462506", location="us-central1", model="gemini-2.5-pro"), name="llm")
pipeline.connect("prompt_builder.prompt", "add_video.prompt")
pipeline.connect("add_video.prompt", "llm.prompt")

# ========== 7. ä¸»é‚è¼¯ ==========
def process_stage2_narratives(video_folder, event_json_folder, output_folder):
    os.makedirs(output_folder, exist_ok=True)
    event_files = sorted([f for f in os.listdir(event_json_folder) if f.endswith("_event.json")])

    for file_name in tqdm(event_files, desc="[Stage 2] æ•˜äº‹ç”Ÿæˆ"):
        event_path = os.path.join(event_json_folder, file_name)
        base_name = file_name.replace("_event.json", "")
        video_path = os.path.join(video_folder, f"{base_name}.mp4")
        
        try:
            with VideoFileClip(video_path) as clip: total_duration = clip.duration
        except: total_duration = 30.0 

        try:
            with open(event_path, 'r', encoding='utf-8') as f: 
                data = json.load(f)
                nested_events = data.get("events", []) if isinstance(data, dict) else data
                video_uri = data.get("segment_video_uri", "") if isinstance(data, dict) else ""
        except: continue

        if not nested_events: continue

        # --- A. æ•¸æ“šæº–å‚™ & èšåˆ (Aggregation) ---
        RALLY_TYPES = ["Exchange", "Smash", "Defend"]
        chunk_events = [] 
        global_id_counter = 0

        # 1. INTRO
        first_chunk_start = parse_time_str(nested_events[0].get("start_time", "0:00.0"))
        intro_limit = int(first_chunk_start * SYLLABLES_PER_SEC)
        if intro_limit >= 8:
             chunk_events.append({
                "global_id": "INTRO",
                "start_sec": 0.0,
                "end_sec": first_chunk_start,
                "limit": intro_limit,
                "info": "é–‹å ´ç©ºç™½"
            })

        last_event_end = 0.0
        
        # 2. è™•ç†èˆ‡èšåˆ
        buffer_chunk = None

        for chunk in nested_events:
            chunk_start = parse_time_str(chunk.get("start_time", "0:00.0"))
            chunk_end = parse_time_str(chunk.get("end_time", "0:00.0"))
            inner_list = chunk.get("events", [])
            if not inner_list: continue
            
            actions_str = " -> ".join([f"{ev.get('player')}{ev.get('action')}" for ev in inner_list])
            
            is_pure_rally = all(ev.get('category') in RALLY_TYPES for ev in inner_list) and \
                            not any(ev.get('category') == 'Score' for ev in inner_list)

            current_chunk = {
                "start": chunk_start,
                "end": chunk_end,
                "info": actions_str,
                "is_rally": is_pure_rally
            }

            # --- èšåˆæ ¸å¿ƒé‚è¼¯ (å«æ™‚é•·é™åˆ¶) ---
            if buffer_chunk:
                # è¨ˆç®—è‹¥åˆä½µå¾Œçš„é ä¼°ç¸½æ™‚é•·
                potential_dur = current_chunk["end"] - buffer_chunk["start"]
                
                # æ¢ä»¶ï¼šé¡å‹ç›¸åŒ ä¸” åˆä½µå¾Œä¸è¶…éæœ€å¤§æ™‚é•· (ä¾‹å¦‚ 6ç§’)
                is_mergeable = (buffer_chunk["is_rally"] and 
                                current_chunk["is_rally"] and 
                                potential_dur <= MAX_RALLY_DURATION)

                if is_mergeable:
                    # åˆä½µ
                    buffer_chunk["end"] = current_chunk["end"]
                    buffer_chunk["info"] += f" -> {current_chunk['info']}"
                else:
                    # ä¸åˆä½µï¼Œå…ˆè¼¸å‡º Buffer
                    dur = buffer_chunk["end"] - buffer_chunk["start"]
                    limit = int(dur * SYLLABLES_PER_SEC)
                    
                    # æª¢æŸ¥æœ€å°æ™‚é•· (é¿å…ç¢å˜´)
                    if limit > 3:
                        chunk_events.append({
                            "global_id": global_id_counter,
                            "start_sec": buffer_chunk["start"],
                            "end_sec": buffer_chunk["end"],
                            "limit": limit,
                            "info": buffer_chunk["info"]
                        })
                        global_id_counter += 1
                    
                    buffer_chunk = current_chunk
            else:
                buffer_chunk = current_chunk

            last_event_end = max(last_event_end, chunk_end)

        # è¿´åœˆçµæŸæ¸…ç©º
        if buffer_chunk:
            dur = buffer_chunk["end"] - buffer_chunk["start"]
            limit = int(dur * SYLLABLES_PER_SEC)
            if limit > 3:
                chunk_events.append({
                    "global_id": global_id_counter,
                    "start_sec": buffer_chunk["start"],
                    "end_sec": buffer_chunk["end"],
                    "limit": limit,
                    "info": buffer_chunk["info"]
                })
                global_id_counter += 1

        # 3. OUTRO
        outro_dur = total_duration - last_event_end
        outro_limit = int(outro_dur * SYLLABLES_PER_SEC)
        if outro_limit >= 8:
            chunk_events.append({
                "global_id": "OUTRO",
                "start_sec": last_event_end,
                "end_sec": total_duration,
                "limit": outro_limit,
                "info": "çµå°¾ç©ºç™½"
            })

        # --- B. å‘¼å« LLM ---
        llm_input_data = []
        for e in chunk_events:
            llm_input_data.append({
                "id": e["global_id"], 
                "constraint": f"é™ {e['limit']} éŸ³ç¯€", 
                "content": e["info"]
            })
        
        try:
            res = pipeline.run({
                "add_video": {"uri": video_uri},
                "prompt_builder": {"event_data": json.dumps(llm_input_data, ensure_ascii=False, indent=2)}
            })
            reply = res["llm"]["replies"][0].strip()
            
            if reply.startswith("```"):
                reply = reply.split("\n", 1)[1]
                if reply.endswith("```"):
                    reply = reply.rsplit("\n", 1)[0]
            
            generated_list = json.loads(reply)
            generated_map = {str(item["id"]): item["text"] for item in generated_list}

        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¤±æ•—: {e}")
            continue

        # --- C. è¼¸å‡ºçµæœ (å«å»é‡) ---
        commentary = []

        for chunk in chunk_events:
            gid = str(chunk["global_id"])
            text_content = generated_map.get(gid)

            if not text_content: continue 

            duration = chunk["end_sec"] - chunk["start_sec"]
            
            # âš¡ï¸âš¡ï¸âš¡ï¸ [æ–°å¢] å¯¬å®¹æˆªæ–·é‚è¼¯ âš¡ï¸âš¡ï¸âš¡ï¸
            estimated_dur = estimate_speech_time(text_content)
            
            # è¨­å®šå¯¬å®¹ä¸Šé™ï¼šå…è¨± TTS åŠ é€Ÿåˆ° 1.2 å€
            # å¦‚æœé ä¼°æ™‚é–“ > (å¯¦éš›æ™‚é–“ * 1.2)ï¼Œä»£è¡¨åŠ é€Ÿä¹Ÿæ•‘ä¸å›ä¾†ï¼Œå¿…é ˆç å­—
            max_acceptable_dur = duration * 1.2 
            
            if estimated_dur > max_acceptable_dur:
                # è¨ˆç®—å®‰å…¨é•·åº¦ (ç åˆ°å‰›å¥½å¯ä»¥ç”¨ 1.2 å€é€Ÿå¿µå®Œçš„é•·åº¦)
                ratio = max_acceptable_dur / estimated_dur
                safe_length = int(len(text_content) * ratio)
                text_content = text_content[:safe_length]
                
                # ä¿®é£¾ï¼šé¿å…æ–·åœ¨é€—è™Ÿæˆ–æ€ªå­—ç¬¦ï¼Œä¸¦åŠ ä¸Šé©šå˜†è™Ÿè¡¨ç¤ºèªæ°£
                text_content = text_content.rstrip("ï¼Œ,ã€") 
                if not text_content.endswith(("ï¼", "ã€‚", "!")):
                    text_content += "ï¼"

            emotion = "æ¿€å‹•" if "æ®ºçƒ" in chunk["info"] or "å¾—åˆ†" in chunk["info"] else "å¹³ç©©"

            # å»é‡åˆä½µé‚è¼¯
            if commentary and len(text_content) >= 2 and len(commentary[-1]["text"]) >= 2:
                check_len = min(5, len(text_content), len(commentary[-1]["text"]))
                if text_content[:check_len] == commentary[-1]["text"][:check_len]:
                    # åˆä½µ
                    commentary[-1]["end_time"] = seconds_to_timecode(chunk["end_sec"])
                    prev_start = parse_time_str(commentary[-1]["start_time"])
                    new_dur = chunk["end_sec"] - prev_start
                    commentary[-1]["time_range"] = format_duration(new_dur)
                    continue

            commentary.append({
                "start_time": seconds_to_timecode(chunk["start_sec"]),
                "end_time": seconds_to_timecode(chunk["end_sec"]),
                "time_range": format_duration(duration),
                "emotion": emotion,
                "text": text_content
            })

        # 4. å„²å­˜
        if commentary:
            with open(os.path.join(output_folder, f"{base_name}.json"), "w", encoding="utf-8") as f:
                json.dump({"segment": f"{base_name}.mp4", "commentary": commentary}, f, ensure_ascii=False, indent=2)
            print(f"âœ… {base_name} å®Œæˆï¼")
        else:
            print(f"âš ï¸ {base_name} ç„¡é©åˆæ—ç™½ã€‚")

if __name__ == "__main__":
    video_folder = "D:/Vs.code/AI_Anchor/backend/video_splitter/badminton_segments"
    event_json_folder = "D:/Vs.code/AI_Anchor/backend/gemini/event_analysis_output"
    output_folder = "D:/Vs.code/AI_Anchor/backend/gemini/final_narratives"

    process_stage2_narratives(video_folder, event_json_folder, output_folder)